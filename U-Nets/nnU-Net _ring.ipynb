{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from tifffile import imread, imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "img_size=400\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "patch_size = img_size\n",
    "num_batches = 50\n",
    "\n",
    "scores = [ 0.,  1.,  2.,  3.]\n",
    "num_classes = len(scores)\n",
    "classes = np.arange(num_classes)\n",
    "\n",
    "\n",
    "#Learningrate Schedule\n",
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, initial_learning_rate):\n",
    "    self.initial_learning_rate = initial_learning_rate\n",
    "    self.name = 'PolynomialLearningRate'\n",
    "\n",
    "  def __call__(self, step):\n",
    "    epoch = step//(num_batches*12.830)\n",
    "    return self.initial_learning_rate*(1 - epoch/epochs)**0.9\n",
    "  \n",
    "  def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"name\": self.name,\n",
    "        }\n",
    "\n",
    "#Optimizer\n",
    "optimizer = keras.optimizers.SGD(MyLRSchedule(0.01),momentum=0.99,nesterov=True, name='SGD')\n",
    "\n",
    "#Loss Function\n",
    "def combo_loss(targets, prediction):\n",
    "    \n",
    "    intersection = K.sum(tf.cast(targets*prediction,tf.float32),axis=(1,2))\n",
    "    union = (K.sum(targets,axis=(1,2)) + K.sum(prediction,axis=(1,2)))\n",
    "    dice = 1 - (2./num_classes)*K.sum(intersection/union,axis=1)\n",
    "    crossentropy = CategoricalCrossentropy()(targets,prediction)\n",
    "\n",
    "    return dice + crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(path_to_label):\n",
    "\n",
    "    label = cv2.resize(imread(path_to_label),(img_size,img_size),interpolation = cv2.INTER_NEAREST)\n",
    "    label = to_categorical(label,num_classes)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(img_names,label_names):\n",
    "    \n",
    "    # Initalise mini batch\n",
    "    images = np.zeros((len(img_names),patch_size,patch_size,3))\n",
    "    labels = np.zeros((len(label_names),patch_size,patch_size,num_classes))\n",
    "\n",
    "    for i, (img_name, label_name) in enumerate(zip(img_names, label_names)):\n",
    "\n",
    "        # append label\n",
    "        labels[i] = load_label(label_name)\n",
    "\n",
    "        # append image\n",
    "        new_img = cv2.resize(cv2.imread(img_name),(400,400)).astype(np.float32)\n",
    "        new_img -= np.mean(new_img)\n",
    "        new_img /= np.var(new_img)\n",
    "        images[i] = new_img\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "train_img_path = 'C:/Users/nwuen/Documents/deepdart_aml/dataset/train'\n",
    "train_label_path = 'T:/deepdart_data/train'\n",
    "\n",
    "\n",
    "    # get filenames\n",
    "train_img_names = sorted(glob.glob(train_img_path+'/**/*'+'.JPG', recursive=True))\n",
    "train_label_names = sorted(glob.glob(train_label_path+'/**/*'+'.tif', recursive=True))\n",
    "\n",
    "train_img_list = [train_img_names[i:i + num_batches*batch_size] for i in range(0, len(train_img_names), num_batches*batch_size)]\n",
    "train_label_list = [train_label_names[i:i + num_batches*batch_size] for i in range(0, len(train_label_names), num_batches*batch_size)]\n",
    "\n",
    "\n",
    "#Validation Data\n",
    "val_img_path = 'C:/Users/nwuen/Documents/deepdart_aml/dataset/val'\n",
    "val_label_path = 'T:/deepdart_data/val'\n",
    "\n",
    "    # get filenames\n",
    "val_img_names = sorted(glob.glob(val_img_path+'/**/*'+'.JPG', recursive=True))\n",
    "val_label_names = sorted(glob.glob(val_label_path+'/**/*'+'.tif', recursive=True))\n",
    "\n",
    "val_img_list = [val_img_names[i:i + num_batches*batch_size] for i in range(0, len(val_img_names), num_batches*batch_size)]\n",
    "val_label_list = [val_label_names[i:i + num_batches*batch_size] for i in range(0, len(val_label_names), num_batches*batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D, Conv2D, Conv2DTranspose, concatenate ,BatchNormalization, LeakyReLU\n",
    "\n",
    "Norm = BatchNormalization\n",
    "LReLU = LeakyReLU\n",
    "Pool = MaxPooling2D\n",
    "\n",
    "def NN_UNet():\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        inputs = keras.Input(shape=(patch_size,patch_size,3))\n",
    "\n",
    "        ###Contracting Part\n",
    "        ##First Block\n",
    "        x = Conv2D(32,3,padding='same')(inputs)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(32,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l1 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Pool(pool_size=2, strides= 2, padding='valid')(l1)\n",
    "        ##Second Block\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l2 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Pool(pool_size= 2, strides= 2, padding='valid')(l2)\n",
    "        ##Third Block\n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l3 = LReLU(alpha= 0.01)(x)\n",
    "        \n",
    "        x = Pool(pool_size= 2, strides= 2, padding='valid')(l3)\n",
    "        ##Fourth Block\n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l4 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Pool(pool_size= 2, strides= 2, padding='valid')(l4)\n",
    "\n",
    "\n",
    "\n",
    "        ##Bottleneck\n",
    "        x = Conv2D(512,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(512,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l5 = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "\n",
    "        ###Expansive Part\n",
    "        ##Fourth Block\n",
    "        x = Conv2DTranspose(256,3,2,padding='same')(l5)\n",
    "        x = concatenate([x,l4])\n",
    "        \n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        ##Third Block\n",
    "        x = Conv2DTranspose(128,3,2,padding='same')(x)\n",
    "        x = concatenate([x,l3])\n",
    "        \n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "        \n",
    "        ##Second Block\n",
    "        x = Conv2DTranspose(64,3,2,padding='same')(x)\n",
    "        x = concatenate([x,l2])\n",
    "\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        #First Block\n",
    "        x = Conv2DTranspose(32,3,2,padding='same')(x)\n",
    "        x = concatenate([x,l1])\n",
    "\n",
    "        x = Conv2D(32,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(32,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        #Final Layer\n",
    "        x = Conv2D(num_classes,1)(x)\n",
    "        outputs = keras.activations.softmax(x)\n",
    "\n",
    "        model = keras.Model(inputs,outputs,name='ringnet')\n",
    "        return model\n",
    "\n",
    "UNet = NN_UNet()\n",
    "UNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_epoch = 0\n",
    "current_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet.compile(\n",
    "    loss = combo_loss,\n",
    "    optimizer = optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "for epoch in range(current_epoch,epochs):\n",
    "    print(f'=======================Start of Epoch {epoch+1}==========================\\n')\n",
    "    \n",
    "    for i in range(current_batch,len(train_img_list)):\n",
    "        #load the data to train and validate\n",
    "        x_train, y_train = load_training_data(train_img_list[i],train_label_list[i])\n",
    "        val_i = i % len(val_img_list)\n",
    "        x_val, y_val = load_training_data(val_img_list[val_i],val_label_list[val_i])\n",
    "        with tf.device(\"cpu:0\"):\n",
    "            history = UNet.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=epoch+1,initial_epoch=epoch,verbose=1,validation_data=(x_val,y_val))\n",
    "        # Log every 5 batches.\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Progress: {((i + 1) * batch_size*num_batches)}/{len(train_img_names)} Steps\"  )\n",
    "            UNet.save_weights('ring.h5')\n",
    "        current_batch +=1\n",
    "    current_batch = 0\n",
    "    current_epoch +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet.load_weights(\"./ring_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = load_training_data(val_img_list[0],val_label_list[0])\n",
    "val = UNet.predict(x_val)[0]\n",
    "val = np.argmax(val,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "ax1.imshow(plt.imread(val_img_list[0][0]))\n",
    "ax1.get_xaxis().set_visible('off')\n",
    "ax1.get_yaxis().set_visible('off')\n",
    "ax1.set_title('Original Image')\n",
    "\n",
    "ax2.imshow(np.dot(y_val[0],scores),cmap='gray')\n",
    "ax2.get_xaxis().set_visible('off')\n",
    "ax2.get_yaxis().set_visible('off')\n",
    "ax2.set_title('True Label')\n",
    "\n",
    "ax3.imshow(val,cmap='gray')\n",
    "ax3.get_xaxis().set_visible('off')\n",
    "ax3.get_yaxis().set_visible('off')\n",
    "ax3.set_title('Prediction')\n",
    "plt.savefig(\"pixel_trained.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aml_projekt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e52e4c377c8bfd8db5d394792a60698c1ae2e0ec2bf08131743554f4058fdfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
