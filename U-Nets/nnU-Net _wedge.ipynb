{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nwuen\\.conda\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from tifffile import imread, imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_folder</th>\n",
       "      <th>img_name</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xy</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1081.JPG</td>\n",
       "      <td>[2297, 3949, 676, 2328]</td>\n",
       "      <td>[[0.4350282485875706, 0.1285310734463277], [0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1082.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1083.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1084.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1085.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0507.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16046</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0508.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16047</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0509.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16048</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0510.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16049</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0511.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16050 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_folder      img_name                     bbox  \\\n",
       "0      d1_02_04_2020  IMG_1081.JPG  [2297, 3949, 676, 2328]   \n",
       "1      d1_02_04_2020  IMG_1082.JPG  [2267, 3803, 759, 2295]   \n",
       "2      d1_02_04_2020  IMG_1083.JPG  [2267, 3803, 759, 2295]   \n",
       "3      d1_02_04_2020  IMG_1084.JPG  [2267, 3803, 759, 2295]   \n",
       "4      d1_02_04_2020  IMG_1085.JPG  [2267, 3803, 759, 2295]   \n",
       "...              ...           ...                      ...   \n",
       "16045  d2_04_05_2020  DSC_0507.JPG   [200, 2849, 969, 3618]   \n",
       "16046  d2_04_05_2020  DSC_0508.JPG   [200, 2849, 969, 3618]   \n",
       "16047  d2_04_05_2020  DSC_0509.JPG   [200, 2849, 969, 3618]   \n",
       "16048  d2_04_05_2020  DSC_0510.JPG   [200, 2849, 969, 3618]   \n",
       "16049  d2_04_05_2020  DSC_0511.JPG   [200, 2849, 969, 3618]   \n",
       "\n",
       "                                                      xy  score  \n",
       "0      [[0.4350282485875706, 0.1285310734463277], [0....    0.0  \n",
       "1      [[0.44162326388888884, 0.12738715277777776], [...   20.0  \n",
       "2      [[0.44162326388888884, 0.12738715277777776], [...   29.0  \n",
       "3      [[0.44162326388888884, 0.12738715277777776], [...   69.0  \n",
       "4      [[0.44162326388888884, 0.12738715277777776], [...    7.0  \n",
       "...                                                  ...    ...  \n",
       "16045  [[0.4369087750204756, 0.1419047415543067], [0....   27.0  \n",
       "16046  [[0.4369087750204756, 0.1419047415543067], [0....   34.0  \n",
       "16047  [[0.4369087750204756, 0.1419047415543067], [0....    1.0  \n",
       "16048  [[0.4369087750204756, 0.1419047415543067], [0....   21.0  \n",
       "16049  [[0.4369087750204756, 0.1419047415543067], [0....   41.0  \n",
       "\n",
       "[16050 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_pickle(f'/home/jacob-relle/Dokumente/deepdart_aml/labelswithscore.pkl')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "img_size=400\n",
    "\n",
    "epochs = 1000\n",
    "batch_size = 2\n",
    "patch_size = img_size\n",
    "num_batches = 2\n",
    "\n",
    "scores = [ 0.,  1.,  2.,  3., 4., 5., 6., 7., 8., 9., 10., \n",
    "          11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 25.]\n",
    "num_classes = len(scores)\n",
    "classes = np.arange(num_classes)\n",
    "\n",
    "\n",
    "#Learningrate Schedule\n",
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, initial_learning_rate):\n",
    "    self.initial_learning_rate = initial_learning_rate\n",
    "    self.name = 'PolynomialLearningRate'\n",
    "\n",
    "  def __call__(self, step):\n",
    "    epoch = step//(num_batches*12.830)\n",
    "    return self.initial_learning_rate*(1 - epoch/epochs)**0.9\n",
    "  \n",
    "  def get_config(self):\n",
    "        return {\n",
    "            \"initial_learning_rate\": self.initial_learning_rate,\n",
    "            \"name\": self.name,\n",
    "        }\n",
    "\n",
    "#Optimizer\n",
    "optimizer = keras.optimizers.SGD(MyLRSchedule(0.01),momentum=0.99,nesterov=True, name='SGD')\n",
    "\n",
    "#Loss Function\n",
    "def combo_loss(targets, prediction):\n",
    "    \n",
    "    intersection = K.sum(tf.cast(targets*prediction,tf.float32),axis=(1,2))\n",
    "    union = (K.sum(targets,axis=(1,2)) + K.sum(prediction,axis=(1,2)))\n",
    "    dice = 1 - (2./num_classes)*K.sum(intersection/union,axis=1)\n",
    "    crossentropy = CategoricalCrossentropy()(targets,prediction)\n",
    "\n",
    "    return dice + crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(path_to_label):\n",
    "\n",
    "    label = cv2.resize(imread(path_to_label),(img_size,img_size),interpolation = cv2.INTER_NEAREST)\n",
    "    \n",
    "    for i, score in enumerate(scores):\n",
    "        label[label == score] = i\n",
    "        \n",
    "    label = to_categorical(label,num_classes)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(img_names,label_names):\n",
    "    \n",
    "    # Initalise mini batch\n",
    "    images = np.zeros((len(img_names),patch_size,patch_size,3))\n",
    "    labels = np.zeros((len(label_names),patch_size,patch_size,num_classes))\n",
    "\n",
    "    for i, (img_name, label_name) in enumerate(zip(img_names, label_names)):\n",
    "\n",
    "        # append label\n",
    "        labels[i] = load_label(label_name)\n",
    "\n",
    "        # append image\n",
    "        new_img = cv2.resize(cv2.imread(img_name),(400,400)).astype(np.float32)\n",
    "        new_img -= np.mean(new_img)\n",
    "        new_img /= np.var(new_img)\n",
    "        images[i] = new_img\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "train_img_path = '/home/jacob-relle/Dokumente/AML Projekt/cropped_images/800/train'\n",
    "train_label_path = '/home/jacob-relle/Dokumente/AML Projekt/deepdart_data_ring/train'\n",
    "\n",
    "\n",
    "    # get filenames\n",
    "train_img_names = sorted(glob.glob(train_img_path+'/**/*'+'.JPG', recursive=True))\n",
    "train_label_names = sorted(glob.glob(train_label_path+'/**/*'+'.tif', recursive=True))\n",
    "\n",
    "train_img_list = [train_img_names[i:i + num_batches*batch_size] for i in range(0, len(train_img_names), num_batches*batch_size)]\n",
    "train_label_list = [train_label_names[i:i + num_batches*batch_size] for i in range(0, len(train_label_names), num_batches*batch_size)]\n",
    "\n",
    "\n",
    "#Validation Data\n",
    "val_img_path = '/home/jacob-relle/Dokumente/AML Projekt/cropped_images/800/val'\n",
    "val_label_path = '/home/jacob-relle/Dokumente/AML Projekt/deepdart_data_ring/val'\n",
    "\n",
    "    # get filenames\n",
    "val_img_names = sorted(glob.glob(val_img_path+'/**/*'+'.JPG', recursive=True))\n",
    "val_label_names = sorted(glob.glob(val_label_path+'/**/*'+'.tif', recursive=True))\n",
    "\n",
    "val_img_list = [val_img_names[i:i + num_batches*batch_size] for i in range(0, len(val_img_names), num_batches*batch_size)]\n",
    "val_label_list = [val_label_names[i:i + num_batches*batch_size] for i in range(0, len(val_label_names), num_batches*batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 800, 800, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 800, 800, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 800, 800, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 800, 800, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 800, 800, 32  9248        ['leaky_re_lu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 800, 800, 32  128        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 800, 800, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 400, 400, 32  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 400, 400, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 400, 400, 64  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 400, 400, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 400, 400, 64  36928       ['leaky_re_lu_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 400, 400, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 400, 400, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 200, 200, 64  0          ['leaky_re_lu_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 200, 200, 12  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 200, 200, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 200, 200, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 200, 200, 12  147584      ['leaky_re_lu_4[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 200, 200, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 200, 200, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 100, 100, 12  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 100, 100, 25  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 100, 100, 25  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 100, 100, 25  0           ['batch_normalization_6[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 100, 100, 25  590080      ['leaky_re_lu_6[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 100, 100, 25  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 100, 100, 25  0           ['batch_normalization_7[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 200, 200, 12  295040     ['leaky_re_lu_7[0][0]']          \n",
      " ose)                           8)                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 200, 200, 25  0           ['conv2d_transpose[0][0]',       \n",
      "                                6)                                'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 200, 200, 12  295040      ['concatenate[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 200, 200, 12  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 200, 200, 12  0           ['batch_normalization_8[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 200, 200, 12  147584      ['leaky_re_lu_8[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 200, 200, 12  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 200, 200, 12  0           ['batch_normalization_9[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 400, 400, 64  73792      ['leaky_re_lu_9[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 400, 400, 12  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                8)                                'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 400, 400, 64  73792       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 400, 400, 64  256        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 400, 400, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 400, 400, 64  36928       ['leaky_re_lu_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 400, 400, 64  256        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 400, 400, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 800, 800, 32  18464      ['leaky_re_lu_11[0][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 800, 800, 64  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 800, 800, 32  18464       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 800, 800, 32  128        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 800, 800, 32  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 800, 800, 32  9248        ['leaky_re_lu_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 800, 800, 32  128        ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 800, 800, 32  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 800, 800, 44  1452        ['leaky_re_lu_13[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (None, 800, 800, 44  0           ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,147,692\n",
      "Trainable params: 2,144,876\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPooling2D, Conv2D, Conv2DTranspose, concatenate ,BatchNormalization, LeakyReLU\n",
    "\n",
    "Norm = BatchNormalization\n",
    "LReLU = LeakyReLU\n",
    "Pool = MaxPooling2D\n",
    "\n",
    "def NN_UNet():\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        inputs = keras.Input(shape=(patch_size,patch_size,3))\n",
    "\n",
    "        ###Contracting Part\n",
    "        ##First Block\n",
    "        x = Conv2D(32,3,padding='same')(inputs)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(32,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l1 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Pool(pool_size=2, strides= 2, padding='valid')(l1)\n",
    "        ##Second Block\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l2 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Pool(pool_size= 2, strides= 2, padding='valid')(l2)\n",
    "        ##Third Block\n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l3 = LReLU(alpha= 0.01)(x)\n",
    "        \n",
    "        x = Pool(pool_size= 2, strides= 2, padding='valid')(l3)\n",
    "        ##Fourth Block\n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l4 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Pool(pool_size= 2, strides= 2, padding='valid')(l4)\n",
    "\n",
    "\n",
    "\n",
    "        ##Bottleneck\n",
    "        x = Conv2D(512,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(512,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        l5 = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "\n",
    "        ###Expansive Part\n",
    "        ##Fourth Block\n",
    "        x = Conv2DTranspose(256,3,2,padding='same')(l5)\n",
    "        x = concatenate([x,l4])\n",
    "        \n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(256,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        ##Third Block\n",
    "        x = Conv2DTranspose(128,3,2,padding='same')(x)\n",
    "        x = concatenate([x,l3])\n",
    "        \n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(128,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "        \n",
    "        ##Second Block\n",
    "        x = Conv2DTranspose(64,3,2,padding='same')(x)\n",
    "        x = concatenate([x,l2])\n",
    "\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(64,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        #First Block\n",
    "        x = Conv2DTranspose(32,3,2,padding='same')(x)\n",
    "        x = concatenate([x,l1])\n",
    "\n",
    "        x = Conv2D(32,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        x = Conv2D(32,3,padding='same')(x)\n",
    "        x = Norm()(x)\n",
    "        x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "        #Final Layer\n",
    "        x = Conv2D(num_classes,1)(x)\n",
    "        outputs = keras.activations.softmax(x)\n",
    "\n",
    "        model = keras.Model(inputs,outputs,name='ringnet')\n",
    "        return model\n",
    "\n",
    "UNet = NN_UNet()\n",
    "UNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_epoch = 0\n",
    "current_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================Start of Epoch 1==========================\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.25 GiB for an array with shape (100, 400, 400, 44) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nwuen\\Documents\\deepdart_aml\\jacob_unet_old.ipynb Zelle 10\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m=======================Start of Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m==========================\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(current_batch,\u001b[39mlen\u001b[39m(train_img_list)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#load the data to train and validate\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     x_train, y_train \u001b[39m=\u001b[39m load_training_data(train_img_list[i],train_label_list[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     val_i \u001b[39m=\u001b[39m i \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(val_img_list)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     x_val, y_val \u001b[39m=\u001b[39m load_training_data(val_img_list[val_i],val_label_list[val_i])\n",
      "\u001b[1;32mc:\\Users\\nwuen\\Documents\\deepdart_aml\\jacob_unet_old.ipynb Zelle 10\u001b[0m in \u001b[0;36mload_training_data\u001b[1;34m(img_names, label_names)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_training_data\u001b[39m(img_names,label_names):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m# Initalise mini batch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(img_names),patch_size,patch_size,\u001b[39m3\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((\u001b[39mlen\u001b[39;49m(label_names),patch_size,patch_size,num_classes))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (img_name, label_name) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(img_names, label_names)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m#x = random.randint(0,800-patch_size)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m#y = random.randint(0,800-patch_size)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         \u001b[39m# append label\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nwuen/Documents/deepdart_aml/jacob_unet_old.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         labels[i] \u001b[39m=\u001b[39m load_label(label_name)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.25 GiB for an array with shape (100, 400, 400, 44) and data type float64"
     ]
    }
   ],
   "source": [
    "UNet.compile(\n",
    "    loss = combo_loss,\n",
    "    optimizer = optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "for epoch in range(current_epoch,epochs):\n",
    "    print(f'=======================Start of Epoch {epoch+1}==========================\\n')\n",
    "    \n",
    "    for i in range(current_batch,len(train_img_list)):\n",
    "        #load the data to train and validate\n",
    "        x_train, y_train = load_training_data(train_img_list[i],train_label_list[i])\n",
    "        val_i = i % len(val_img_list)\n",
    "        x_val, y_val = load_training_data(val_img_list[val_i],val_label_list[val_i])\n",
    "        with tf.device(\"cpu:0\"):\n",
    "            history = UNet.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=epoch+1,initial_epoch=epoch,verbose=1,validation_data=(x_val,y_val))\n",
    "        # Log every 5 batches.\n",
    "        if i % 5 == 0:\n",
    "            print(f\"Progress: {((i + 1) * batch_size*num_batches)}/{len(train_img_names)} Steps\"  )\n",
    "            UNet.save_weights('segment.h5')\n",
    "        current_batch +=1\n",
    "    current_batch = 0\n",
    "    current_epoch +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNet.load_weights(\"./segment_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = load_training_data(val_img_list[0],val_label_list[0])\n",
    "val = UNet.predict(x_val)[0]\n",
    "val = np.argmax(val,axis=2)\n",
    "for i, score in enumerate(scores):\n",
    "    val[val==i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3)\n",
    "ax1.imshow(plt.imread(val_img_list[0][0]))\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "ax1.set_title('Original Image')\n",
    "\n",
    "ax2.imshow(np.dot(y_val[0],scores),cmap='gray')\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "ax2.set_title('True Label')\n",
    "\n",
    "ax3.imshow(val,cmap='gray')\n",
    "ax3.get_xaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "ax3.set_title('Prediction')\n",
    "plt.savefig(\"pixel_trained.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aml_projekt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e52e4c377c8bfd8db5d394792a60698c1ae2e0ec2bf08131743554f4058fdfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
