{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 21:16:17.443716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-16 21:16:17.443793: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils import image_dataset_from_directory, to_categorical\n",
    "import os, glob\n",
    "from tifffile import imread, imwrite\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "labels = pd.read_pickle(f'{os.environ[\"HOME\"]}/Dokumente/AML Projekt/labels_pkl/labels.pkl')\n",
    "for i in range(len(labels)): ##Ã¼ber len(labels)\n",
    "    im_old = imread(f'{os.environ[\"HOME\"]}/Dokumente/AML Projekt/cropped_labels/{labels[\"img_folder\"][i]}/{os.path.splitext(labels[\"img_name\"][i])[0]}.tif')\n",
    "    im_new = to_categorical(im_old)\n",
    "    imwrite(f'{os.environ[\"HOME\"]}/Dokumente/AML Projekt/categorical_labels/{labels[\"img_folder\"][i]}/{os.path.splitext(labels[\"img_name\"][i])[0]}.tif',im_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "num_batches = 250\n",
    "batch_size = 8\n",
    "\n",
    "patch_size = 256\n",
    "\n",
    "num_classes = 44\n",
    "classes = np.arange(44)\n",
    "scores = [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
    "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 24., 25., 26.,\n",
    "       27., 28., 30., 32., 33., 34., 36., 38., 39., 40., 42., 45., 48.,\n",
    "       50., 51., 54., 57., 60.]\n",
    "\n",
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, initial_learning_rate):\n",
    "    self.initial_learning_rate = initial_learning_rate\n",
    "\n",
    "  def __call__(self, epoch):\n",
    "     return (self.initial_learning_rate - epoch/epochs)**0.9\n",
    "\n",
    "def DiceLoss(targets, inputs, smooth=1e-6):\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = keras.backend.flatten(inputs)\n",
    "    targets = keras.backend.flatten(targets)\n",
    "    \n",
    "    intersection = keras.backend.sum(keras.backend.dot(targets, inputs))\n",
    "    dice = (2*intersection + smooth) / (keras.backend.sum(targets) + keras.backend.sum(inputs) + smooth)\n",
    "    return 1 - dice + keras.losses.CategoricalCrossentropy()(targets,inputs)\n",
    "\n",
    "loss = DiceLoss\n",
    "\n",
    "optimizer = keras.optimizers.SGD(MyLRSchedule(1.),momentum=0.99,nesterov=True, name='SGD')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(path_to_label):\n",
    "\n",
    "    label = imread(path_to_label)\n",
    "    \n",
    "    for i, score in enumerate(scores):\n",
    "        label[label == score] = i\n",
    "\n",
    "    label = to_categorical(label,num_classes)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(img_dir, label_dir):\n",
    "    \n",
    "    # get filenames\n",
    "    img_names = sorted(glob.glob(img_dir+'/**/*'+'.JPG', recursive=True))\n",
    "    label_names = sorted(glob.glob(label_dir+'/**/*'+'.tif', recursive=True))\n",
    "\n",
    "\n",
    "    # load first label\n",
    "    labels = np.zeros((batch_size,patch_size,patch_size,num_classes))\n",
    "\n",
    "    # Initalise mini batch\n",
    "    images = np.zeros((batch_size,patch_size,patch_size,3))\n",
    "\n",
    "    for i, (img_name, label_name) in enumerate(zip(img_names[0:batch_size], label_names[0:batch_size])):\n",
    "\n",
    "        # append label\n",
    "        labels[i] = load_label(label_name)[400-128:400+128,400-128:400+128]\n",
    "\n",
    "        # append image\n",
    "        new_img = plt.imread(img_name)[400-128:400+128,400-128:400+128]\n",
    "        new_img = new_img.astype(np.float32)\n",
    "        new_img -= np.amin(new_img)\n",
    "        new_img /= np.amax(new_img)\n",
    "        images[i] = new_img\n",
    "        \n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data to train and validate\n",
    "\n",
    "train_img_path = '/home/jacob-relle/Dokumente/AML Projekt/cropped_images/800/d1_02_04_2020'\n",
    "train_label_path = '/home/jacob-relle/Dokumente/AML Projekt/cropped_labels/d1_02_04_2020'\n",
    "\n",
    "val_img_path = '/home/jacob-relle/Dokumente/AML Projekt/cropped_images/800/d1_02_06_2020'\n",
    "val_label_path = '/home/jacob-relle/Dokumente/AML Projekt/cropped_labels/d1_02_06_2020'\n",
    "\n",
    "x_train, y_train = load_training_data(train_img_path,train_label_path)\n",
    "x_val, y_val = load_training_data(val_img_path,val_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 256, 256, 44)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 21:16:24.813978: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-08-16 21:16:24.814010: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Murasame): /proc/driver/nvidia/version does not exist\n",
      "2022-08-16 21:16:24.815174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 256, 256, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 32  9248        ['leaky_re_lu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 32  128        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 256, 256, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 32  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 64  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 128, 128, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 64  36928       ['leaky_re_lu_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 128, 128, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)  0           ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 128)  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 64, 64, 128)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 128)  147584      ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 64, 64, 128)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 32, 32, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 256)  590080      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 256)  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 32, 32, 256)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 128)  295040     ['leaky_re_lu_7[0][0]']          \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 64, 64, 128)  0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 64, 64, 128)  147584      ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 64, 64, 128)  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 64, 64, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 64  73792      ['leaky_re_lu_9[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 12  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                8)                                'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 64  256        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 128, 128, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 128, 128, 64  36928       ['leaky_re_lu_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 128, 128, 64  256        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 128, 128, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 32  18464      ['leaky_re_lu_11[0][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 64  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 32  18464       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256, 256, 32  128        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 256, 256, 32  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 256, 256, 32  9248        ['leaky_re_lu_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 256, 256, 32  128        ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 256, 256, 32  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 44  1452        ['leaky_re_lu_13[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (None, 256, 256, 44  0           ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,147,692\n",
      "Trainable params: 2,144,876\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPooling2D, Conv2D, Conv2DTranspose, concatenate ,BatchNormalization, LeakyReLU\n",
    "\n",
    "Norm = BatchNormalization\n",
    "LReLU = LeakyReLU\n",
    "Pool = MaxPooling2D\n",
    "\n",
    "def NN_UNet():\n",
    "    inputs = keras.Input(shape=(patch_size,patch_size,3))\n",
    "\n",
    "    #Downsampeling\n",
    "    x = Conv2D(32,3,padding='same')(inputs)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(32,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l1 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Pool(pool_size= 2, strides= 2, padding='valid')(l1)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l2 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Pool(pool_size= 2, strides= 2, padding='valid')(l2)\n",
    "\n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l3 = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "    x = Pool(pool_size= 2, strides= 2, padding='valid')(l3)\n",
    "\n",
    "    x = Conv2D(256,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(256,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l4 = LReLU(alpha= 0.01)(x)\n",
    "    '''\n",
    "    x = Pool(pool_size= 2, strides= 2, padding='valid')(l4)\n",
    "    \n",
    "    #Bottleneck\n",
    "    x = Conv2D(512,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(512,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l5 = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "    #Upsampleing\n",
    "    x = Conv2DTranspose(256,3,2,padding='same')(l5)\n",
    "    x = concatenate([x,l4])\n",
    "\n",
    "    x = Conv2D(256,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(256,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "    '''\n",
    "\n",
    "    x = Conv2DTranspose(128,3,2,padding='same')(l4)\n",
    "    x = concatenate([x,l3])\n",
    "    \n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64,3,2,padding='same')(x)\n",
    "    x = concatenate([x,l2])\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2DTranspose(32,3,2,padding='same')(x)\n",
    "    x = concatenate([x,l1])\n",
    "\n",
    "    x = Conv2D(32,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(32,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(44,1)(x)\n",
    "    outputs = keras.activations.softmax(x)\n",
    "\n",
    "    model = keras.Model(inputs,outputs,name='U-Net')\n",
    "    return model\n",
    "\n",
    "UNet = NN_UNet()\n",
    "UNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 4.0632 - accuracy: 0.0272 - val_loss: 7.0680 - val_accuracy: 0.0340\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 8s 8s/step - loss: 3.6788 - accuracy: 0.0576 - val_loss: 10.7765 - val_accuracy: 0.0592\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.0806 - accuracy: 0.1296 - val_loss: 26.0938 - val_accuracy: 0.0598\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.6473 - accuracy: 0.1418 - val_loss: 51.1291 - val_accuracy: 0.0573\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.4483 - accuracy: 0.1497 - val_loss: 63.5048 - val_accuracy: 0.0587\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3386 - accuracy: 0.1477 - val_loss: 121.9817 - val_accuracy: 0.0449\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.3139 - accuracy: 0.2228 - val_loss: 274.8125 - val_accuracy: 0.0528\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3271 - accuracy: 0.1689 - val_loss: 992.6693 - val_accuracy: 0.0390\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.2799 - accuracy: 0.2052 - val_loss: 2817.6575 - val_accuracy: 0.0323\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.2583 - accuracy: 0.1841 - val_loss: 4059.8054 - val_accuracy: 0.0320\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.2605 - accuracy: 0.1794 - val_loss: 10737.4521 - val_accuracy: 0.0320\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3530 - accuracy: 0.1921 - val_loss: 14648.2246 - val_accuracy: 0.0320\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.2732 - accuracy: 0.1856 - val_loss: 10954.3613 - val_accuracy: 0.0672\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.1523 - accuracy: 0.1994 - val_loss: 28201.4023 - val_accuracy: 0.0590\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.3616 - accuracy: 0.2130 - val_loss: 39998.7344 - val_accuracy: 0.0598\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.3054 - accuracy: 0.2321 - val_loss: 123747.5625 - val_accuracy: 0.0602\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.2710 - accuracy: 0.2283 - val_loss: 240696.7969 - val_accuracy: 0.0597\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.1450 - accuracy: 0.2375 - val_loss: 1036919.3750 - val_accuracy: 0.0594\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.8905 - accuracy: 0.2733 - val_loss: 1136543.1250 - val_accuracy: 0.0609\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.8182 - accuracy: 0.2859 - val_loss: 5557776.0000 - val_accuracy: 0.0594\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.8225 - accuracy: 0.2999 - val_loss: 3889976.5000 - val_accuracy: 0.0616\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.8226 - accuracy: 0.2754 - val_loss: 12653329.0000 - val_accuracy: 0.0594\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.7264 - accuracy: 0.3334 - val_loss: 12867880.0000 - val_accuracy: 0.0658\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.6362 - accuracy: 0.3660 - val_loss: 18306714.0000 - val_accuracy: 0.0594\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.5814 - accuracy: 0.3948 - val_loss: 19928964.0000 - val_accuracy: 0.0628\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.5222 - accuracy: 0.4302 - val_loss: 23612642.0000 - val_accuracy: 0.0604\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.4775 - accuracy: 0.4210 - val_loss: 25591100.0000 - val_accuracy: 0.0614\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.4358 - accuracy: 0.4243 - val_loss: 24115314.0000 - val_accuracy: 0.0606\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.3921 - accuracy: 0.4422 - val_loss: 28498232.0000 - val_accuracy: 0.0598\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.3822 - accuracy: 0.4338 - val_loss: 27608656.0000 - val_accuracy: 0.0771\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.3864 - accuracy: 0.4318 - val_loss: 41570772.0000 - val_accuracy: 0.0594\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.5335 - accuracy: 0.3945 - val_loss: 60770176.0000 - val_accuracy: 0.0604\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.2601 - accuracy: 0.4785 - val_loss: 60770932.0000 - val_accuracy: 0.0594\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 1.2582 - accuracy: 0.4890 - val_loss: 102903944.0000 - val_accuracy: 0.0594\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.5541 - accuracy: 0.3902 - val_loss: 33245922.0000 - val_accuracy: 0.0594\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.7187 - accuracy: 0.3914 - val_loss: 222117744.0000 - val_accuracy: 0.0594\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.5144 - accuracy: 0.4376 - val_loss: 140454928.0000 - val_accuracy: 0.0594\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.2252 - accuracy: 0.4684 - val_loss: 194989168.0000 - val_accuracy: 0.0594\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 1.1300 - accuracy: 0.5245 - val_loss: 217076192.0000 - val_accuracy: 0.0594\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 1.0868 - accuracy: 0.5448 - val_loss: 217843984.0000 - val_accuracy: 0.0594\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.0495 - accuracy: 0.5713 - val_loss: 209075536.0000 - val_accuracy: 0.0594\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.0127 - accuracy: 0.5918 - val_loss: 197146144.0000 - val_accuracy: 0.0594\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.9814 - accuracy: 0.6092 - val_loss: 179634176.0000 - val_accuracy: 0.0594\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.9537 - accuracy: 0.6257 - val_loss: 159861744.0000 - val_accuracy: 0.0594\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.9243 - accuracy: 0.6435 - val_loss: 143767360.0000 - val_accuracy: 0.0594\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.8937 - accuracy: 0.6561 - val_loss: 131833232.0000 - val_accuracy: 0.0594\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.8641 - accuracy: 0.6678 - val_loss: 125750824.0000 - val_accuracy: 0.0594\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.8358 - accuracy: 0.6809 - val_loss: 123154560.0000 - val_accuracy: 0.0594\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.8078 - accuracy: 0.6951 - val_loss: 119760328.0000 - val_accuracy: 0.0594\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.7792 - accuracy: 0.7096 - val_loss: 114075008.0000 - val_accuracy: 0.0594\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.7503 - accuracy: 0.7244 - val_loss: 105290160.0000 - val_accuracy: 0.0594\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.7222 - accuracy: 0.7367 - val_loss: 94049640.0000 - val_accuracy: 0.0594\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6953 - accuracy: 0.7474 - val_loss: 82022456.0000 - val_accuracy: 0.0603\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6701 - accuracy: 0.7582 - val_loss: 70938584.0000 - val_accuracy: 0.0612\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6464 - accuracy: 0.7691 - val_loss: 62212824.0000 - val_accuracy: 0.0617\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6272 - accuracy: 0.7780 - val_loss: 53780252.0000 - val_accuracy: 0.0636\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6263 - accuracy: 0.7862 - val_loss: 52146696.0000 - val_accuracy: 0.0629\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6932 - accuracy: 0.7500 - val_loss: 40660516.0000 - val_accuracy: 0.0820\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.9382 - accuracy: 0.6855 - val_loss: 55960372.0000 - val_accuracy: 0.0605\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.8387 - accuracy: 0.7231 - val_loss: 51175556.0000 - val_accuracy: 0.0605\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6178 - accuracy: 0.7893 - val_loss: 44191748.0000 - val_accuracy: 0.0607\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5929 - accuracy: 0.7949 - val_loss: 38883572.0000 - val_accuracy: 0.0620\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.5679 - accuracy: 0.8151 - val_loss: 34887944.0000 - val_accuracy: 0.0690\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5443 - accuracy: 0.8276 - val_loss: 32083290.0000 - val_accuracy: 0.0818\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.5221 - accuracy: 0.8373 - val_loss: 30131674.0000 - val_accuracy: 0.0817\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.4996 - accuracy: 0.8502 - val_loss: 28643314.0000 - val_accuracy: 0.0765\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.4778 - accuracy: 0.8632 - val_loss: 27542404.0000 - val_accuracy: 0.0730\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4573 - accuracy: 0.8737 - val_loss: 26941574.0000 - val_accuracy: 0.0709\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4387 - accuracy: 0.8832 - val_loss: 26874164.0000 - val_accuracy: 0.0647\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4224 - accuracy: 0.8915 - val_loss: 27209952.0000 - val_accuracy: 0.0557\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4076 - accuracy: 0.8975 - val_loss: 27709742.0000 - val_accuracy: 0.0524\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3939 - accuracy: 0.9009 - val_loss: 28138808.0000 - val_accuracy: 0.0528\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3816 - accuracy: 0.9036 - val_loss: 28457438.0000 - val_accuracy: 0.0528\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3708 - accuracy: 0.9062 - val_loss: 28782640.0000 - val_accuracy: 0.0521\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3612 - accuracy: 0.9088 - val_loss: 29192244.0000 - val_accuracy: 0.0517\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3520 - accuracy: 0.9115 - val_loss: 29590476.0000 - val_accuracy: 0.0514\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3429 - accuracy: 0.9141 - val_loss: 29836352.0000 - val_accuracy: 0.0513\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.3343 - accuracy: 0.9169 - val_loss: 29892470.0000 - val_accuracy: 0.0513\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.3262 - accuracy: 0.9194 - val_loss: 29743786.0000 - val_accuracy: 0.0510\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4507/87707025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#test_scores = model.evaluate(x_test,y_test,verbose=2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aml_projekt/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "UNet.compile(\n",
    "    loss = keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer = optimizer,\n",
    "    metrics=[\"accuracy\"]    \n",
    ")\n",
    "\n",
    "history = UNet.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_val,y_val))\n",
    "#test_scores = model.evaluate(x_test,y_test,verbose=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = UNet.predict(x_train)\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_folder</th>\n",
       "      <th>img_name</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xy</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1081.JPG</td>\n",
       "      <td>[2297, 3949, 676, 2328]</td>\n",
       "      <td>[[0.4350282485875706, 0.1285310734463277], [0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1082.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1083.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1084.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1085.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0507.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16046</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0508.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16047</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0509.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16048</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0510.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16049</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0511.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16050 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_folder      img_name                     bbox  \\\n",
       "0      d1_02_04_2020  IMG_1081.JPG  [2297, 3949, 676, 2328]   \n",
       "1      d1_02_04_2020  IMG_1082.JPG  [2267, 3803, 759, 2295]   \n",
       "2      d1_02_04_2020  IMG_1083.JPG  [2267, 3803, 759, 2295]   \n",
       "3      d1_02_04_2020  IMG_1084.JPG  [2267, 3803, 759, 2295]   \n",
       "4      d1_02_04_2020  IMG_1085.JPG  [2267, 3803, 759, 2295]   \n",
       "...              ...           ...                      ...   \n",
       "16045  d2_04_05_2020  DSC_0507.JPG   [200, 2849, 969, 3618]   \n",
       "16046  d2_04_05_2020  DSC_0508.JPG   [200, 2849, 969, 3618]   \n",
       "16047  d2_04_05_2020  DSC_0509.JPG   [200, 2849, 969, 3618]   \n",
       "16048  d2_04_05_2020  DSC_0510.JPG   [200, 2849, 969, 3618]   \n",
       "16049  d2_04_05_2020  DSC_0511.JPG   [200, 2849, 969, 3618]   \n",
       "\n",
       "                                                      xy  score  \n",
       "0      [[0.4350282485875706, 0.1285310734463277], [0....    0.0  \n",
       "1      [[0.44162326388888884, 0.12738715277777776], [...   20.0  \n",
       "2      [[0.44162326388888884, 0.12738715277777776], [...   29.0  \n",
       "3      [[0.44162326388888884, 0.12738715277777776], [...   69.0  \n",
       "4      [[0.44162326388888884, 0.12738715277777776], [...    7.0  \n",
       "...                                                  ...    ...  \n",
       "16045  [[0.4369087750204756, 0.1419047415543067], [0....   27.0  \n",
       "16046  [[0.4369087750204756, 0.1419047415543067], [0....   34.0  \n",
       "16047  [[0.4369087750204756, 0.1419047415543067], [0....    1.0  \n",
       "16048  [[0.4369087750204756, 0.1419047415543067], [0....   21.0  \n",
       "16049  [[0.4369087750204756, 0.1419047415543067], [0....   41.0  \n",
       "\n",
       "[16050 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "pd.read_pickle(f'{os.environ[\"HOME\"]}/Dokumente/deepdart_aml/labelswithscore.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('aml_projekt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e52e4c377c8bfd8db5d394792a60698c1ae2e0ec2bf08131743554f4058fdfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
