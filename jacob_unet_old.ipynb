{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "from tifffile import imread, imwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd \n",
    "labels = pd.read_pickle(f'{os.environ[\"HOME\"]}/Dokumente/AML Projekt/labels_pkl/labels.pkl')\n",
    "for i in range(len(labels)): ##Ã¼ber len(labels)\n",
    "    im_old = imread(f'{os.environ[\"HOME\"]}/Dokumente/AML Projekt/cropped_labels/{labels[\"img_folder\"][i]}/{os.path.splitext(labels[\"img_name\"][i])[0]}.tif')\n",
    "    im_new = to_categorical(im_old)\n",
    "    imwrite(f'{os.environ[\"HOME\"]}/Dokumente/AML Projekt/categorical_labels/{labels[\"img_folder\"][i]}/{os.path.splitext(labels[\"img_name\"][i])[0]}.tif',im_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "num_batches = 250\n",
    "batch_size = 2\n",
    "\n",
    "patch_size = 800\n",
    "\n",
    "num_classes = 44\n",
    "classes = np.arange(44)\n",
    "scores = [ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
    "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 24., 25., 26.,\n",
    "       27., 28., 30., 32., 33., 34., 36., 38., 39., 40., 42., 45., 48.,\n",
    "       50., 51., 54., 57., 60.]\n",
    "\n",
    "\n",
    "class MyLRSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, initial_learning_rate):\n",
    "    self.initial_learning_rate = initial_learning_rate\n",
    "\n",
    "  def __call__(self, epoch):\n",
    "    return self.initial_learning_rate*( 1- epoch/epochs)**0.9\n",
    "\n",
    "optimizer = keras.optimizers.SGD(MyLRSchedule(0.01),momentum=0.99,nesterov=True, name='SGD')\n",
    "#optimizer = Adam(learning_rate=3e-4)\n",
    "\n",
    "#class MyLoss(tf.keras.losses.Loss):\n",
    "def MyLoss(targets, prediction):\n",
    "    \n",
    "    intersection = keras.backend.sum(tf.cast(targets*prediction,tf.float32),axis=(1,2))\n",
    "    dice = (-2/num_classes)*keras.backend.sum(intersection/(keras.backend.sum(targets,axis=(1,2)) + keras.backend.sum(prediction,axis=(1,2))),axis=1)\n",
    "    Crossentropy = CategoricalCrossentropy()(targets,prediction)\n",
    "\n",
    "    return dice + Crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(path_to_label):\n",
    "\n",
    "    label = imread(path_to_label)\n",
    "    \n",
    "    for i, score in enumerate(scores):\n",
    "        label[label == score] = i\n",
    "\n",
    "    label = to_categorical(label,num_classes)\n",
    "\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(img_dir, label_dir,batch_number=0):\n",
    "    \n",
    "    # get filenames\n",
    "    img_names = sorted(glob.glob(img_dir+'/**/*'+'.JPG', recursive=True))\n",
    "    label_names = sorted(glob.glob(label_dir+'/**/*'+'.tif', recursive=True))\n",
    "\n",
    "    # Initalise mini batch\n",
    "    images = np.zeros((batch_size,patch_size,patch_size,3))\n",
    "    labels = np.zeros((batch_size,patch_size,patch_size,num_classes))\n",
    "\n",
    "    batch_start = batch_number*batch_size\n",
    "    batch_end = batch_start + batch_size\n",
    "\n",
    "    if batch_start >= len(img_names):\n",
    "        batch_start = batch_start%len(img_names)\n",
    "        batch_end = batch_start +batch_size\n",
    "    if batch_end >=len(img_names):\n",
    "        batch_end = len(img_names)\n",
    "\n",
    "    for i, (img_name, label_name) in enumerate(zip(img_names[batch_start:batch_end], label_names[batch_start:batch_end])):\n",
    "\n",
    "        x = random.randint(0,800-patch_size)\n",
    "        y = random.randint(0,800-patch_size)\n",
    "\n",
    "        # append label\n",
    "        labels[i] = load_label(label_name)[x:x+patch_size,y:y+patch_size]\n",
    "\n",
    "        # append image\n",
    "        new_img = cv2.imread(img_name)[x:x+patch_size,y:y+patch_size].astype(np.float32)\n",
    "        new_img -= np.mean(new_img)\n",
    "        new_img /= np.var(new_img)\n",
    "        images[i] = new_img\n",
    "        \n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_path = 'C:/Users/nwuen/Documents/deepdart_aml/dataset/cropped_images/800/d1_02_04_2020'\n",
    "train_label_path = 'T:/deepdart_data/d1_02_04_2020'\n",
    "\n",
    "val_img_path = 'C:/Users/nwuen/Documents/deepdart_aml/dataset/cropped_images/800/d1_02_06_2020'\n",
    "val_label_path = 'T:/deepdart_data/d1_02_06_2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"U-Net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 400, 400, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 400, 400, 32  896         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 400, 400, 32  128        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 400, 400, 32  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 400, 400, 32  9248        ['leaky_re_lu[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 400, 400, 32  128        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 400, 400, 32  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 200, 200, 32  0           ['leaky_re_lu_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 200, 200, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 200, 200, 64  256        ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 200, 200, 64  0           ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 200, 200, 64  36928       ['leaky_re_lu_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 200, 200, 64  256        ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 200, 200, 64  0           ['batch_normalization_3[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 100, 100, 64  0          ['leaky_re_lu_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 100, 100, 12  73856       ['max_pooling2d_1[0][0]']        \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 100, 100, 12  512        ['conv2d_4[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 100, 100, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 100, 100, 12  147584      ['leaky_re_lu_4[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 100, 100, 12  512        ['conv2d_5[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 100, 100, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 50, 50, 128)  0          ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 50, 50, 256)  295168      ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 50, 50, 256)  1024       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 50, 50, 256)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 50, 50, 256)  590080      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 50, 50, 256)  1024       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 50, 50, 256)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 100, 100, 12  295040     ['leaky_re_lu_7[0][0]']          \n",
      " ose)                           8)                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 100, 100, 25  0           ['conv2d_transpose[0][0]',       \n",
      "                                6)                                'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 100, 100, 12  295040      ['concatenate[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 100, 100, 12  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 100, 100, 12  0           ['batch_normalization_8[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 100, 100, 12  147584      ['leaky_re_lu_8[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 100, 100, 12  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 100, 100, 12  0           ['batch_normalization_9[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 200, 200, 64  73792      ['leaky_re_lu_9[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 200, 200, 12  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                8)                                'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 200, 200, 64  73792       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 200, 200, 64  256        ['conv2d_10[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 200, 200, 64  0           ['batch_normalization_10[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 200, 200, 64  36928       ['leaky_re_lu_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 200, 200, 64  256        ['conv2d_11[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 200, 200, 64  0           ['batch_normalization_11[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 400, 400, 32  18464      ['leaky_re_lu_11[0][0]']         \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 400, 400, 64  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                )                                 'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 400, 400, 32  18464       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 400, 400, 32  128        ['conv2d_12[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 400, 400, 32  0           ['batch_normalization_12[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 400, 400, 32  9248        ['leaky_re_lu_12[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 400, 400, 32  128        ['conv2d_13[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 400, 400, 32  0           ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 400, 400, 44  1452        ['leaky_re_lu_13[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)     (None, 400, 400, 44  0           ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,147,692\n",
      "Trainable params: 2,144,876\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPooling2D, Conv2D, Conv2DTranspose, concatenate ,BatchNormalization, LeakyReLU\n",
    "\n",
    "Norm = BatchNormalization\n",
    "LReLU = LeakyReLU\n",
    "Pool = MaxPooling2D\n",
    "\n",
    "def NN_UNet():\n",
    "    inputs = keras.Input(shape=(patch_size,patch_size,3))\n",
    "\n",
    "    #Downsampeling\n",
    "    x = Conv2D(32,3,padding='same')(inputs)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(32,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l1 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Pool(pool_size=2, strides= 2, padding='valid')(l1)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l2 = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Pool(pool_size= 2, strides= 2, padding='valid')(l2)\n",
    "\n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l3 = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "    x = Pool(pool_size= 2, strides= 2, padding='valid')(l3)\n",
    "\n",
    "    x = Conv2D(256,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(256,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    l4 = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    x = Conv2DTranspose(128,3,2,padding='same')(l4)\n",
    "    x = concatenate([x,l3])\n",
    "    \n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(128,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64,3,2,padding='same')(x)\n",
    "    x = concatenate([x,l2])\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(64,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2DTranspose(32,3,2,padding='same')(x)\n",
    "    x = concatenate([x,l1])\n",
    "\n",
    "    x = Conv2D(32,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(32,3,padding='same')(x)\n",
    "    x = Norm()(x)\n",
    "    x = LReLU(alpha= 0.01)(x)\n",
    "\n",
    "    x = Conv2D(44,1)(x)\n",
    "    outputs = keras.activations.softmax(x)\n",
    "\n",
    "    model = keras.Model(inputs,outputs,name='U-Net')\n",
    "    return model\n",
    "\n",
    "UNet = NN_UNet()\n",
    "UNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4.0810 - accuracy: 0.0165 - val_loss: 3.7725 - val_accuracy: 0.0053\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 3.9675 - accuracy: 0.0392 - val_loss: 3.7700 - val_accuracy: 0.2325\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 3.8699 - accuracy: 0.0450 - val_loss: 3.7661 - val_accuracy: 0.3338\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 3.7702 - accuracy: 0.0573 - val_loss: 3.7609 - val_accuracy: 0.3329\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 3.6713 - accuracy: 0.0783 - val_loss: 3.7543 - val_accuracy: 0.3329\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 3.5743 - accuracy: 0.1135 - val_loss: 3.7466 - val_accuracy: 0.3329\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 3.4708 - accuracy: 0.1555 - val_loss: 3.7376 - val_accuracy: 0.3329\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 3.3565 - accuracy: 0.2013 - val_loss: 3.7273 - val_accuracy: 0.3329\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 3.2397 - accuracy: 0.2436 - val_loss: 3.7157 - val_accuracy: 0.3329\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 3.1229 - accuracy: 0.2818 - val_loss: 3.7029 - val_accuracy: 0.3329\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 3.0066 - accuracy: 0.3111 - val_loss: 3.6888 - val_accuracy: 0.3329\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 2.8956 - accuracy: 0.3255 - val_loss: 3.6735 - val_accuracy: 0.3329\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 2.7921 - accuracy: 0.3319 - val_loss: 3.6572 - val_accuracy: 0.3329\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 2.6973 - accuracy: 0.3362 - val_loss: 3.6400 - val_accuracy: 0.3329\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.6095 - accuracy: 0.3395 - val_loss: 3.6220 - val_accuracy: 0.3329\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 2.5279 - accuracy: 0.3423 - val_loss: 3.6033 - val_accuracy: 0.3329\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.4544 - accuracy: 0.3454 - val_loss: 3.5838 - val_accuracy: 0.3329\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.3877 - accuracy: 0.3473 - val_loss: 3.5639 - val_accuracy: 0.3329\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 2.3268 - accuracy: 0.3479 - val_loss: 3.5435 - val_accuracy: 0.3329\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 2.2707 - accuracy: 0.3466 - val_loss: 3.5231 - val_accuracy: 0.3329\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 2.2198 - accuracy: 0.3455 - val_loss: 3.5026 - val_accuracy: 0.3329\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 2.1740 - accuracy: 0.3444 - val_loss: 3.4826 - val_accuracy: 0.3329\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 2.1334 - accuracy: 0.3451 - val_loss: 3.4628 - val_accuracy: 0.3329\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.0979 - accuracy: 0.3464 - val_loss: 3.4434 - val_accuracy: 0.3329\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 2.0660 - accuracy: 0.3478 - val_loss: 3.4243 - val_accuracy: 0.3329\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 2.0375 - accuracy: 0.3500 - val_loss: 3.4056 - val_accuracy: 0.3329\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 154ms/step - loss: 2.0107 - accuracy: 0.3532 - val_loss: 3.3874 - val_accuracy: 0.3329\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.9831 - accuracy: 0.3577 - val_loss: 3.3692 - val_accuracy: 0.3329\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.9575 - accuracy: 0.3613 - val_loss: 3.3513 - val_accuracy: 0.3329\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.9353 - accuracy: 0.3620 - val_loss: 3.3363 - val_accuracy: 0.3329\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.9585 - accuracy: 0.3635 - val_loss: 3.3025 - val_accuracy: 0.3329\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 2.0584 - accuracy: 0.3549 - val_loss: 3.2760 - val_accuracy: 0.3328\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.9879 - accuracy: 0.3519 - val_loss: 3.2548 - val_accuracy: 0.3315\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.9586 - accuracy: 0.3491 - val_loss: 3.2388 - val_accuracy: 0.3363\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.9314 - accuracy: 0.3474 - val_loss: 3.2280 - val_accuracy: 0.3364\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.9063 - accuracy: 0.3477 - val_loss: 3.2236 - val_accuracy: 0.3420\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.8816 - accuracy: 0.3494 - val_loss: 3.2261 - val_accuracy: 0.3380\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.8568 - accuracy: 0.3536 - val_loss: 3.2275 - val_accuracy: 0.3337\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.8456 - accuracy: 0.3772 - val_loss: 3.2095 - val_accuracy: 0.3319\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.8180 - accuracy: 0.4026 - val_loss: 3.2118 - val_accuracy: 0.3294\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.8035 - accuracy: 0.4069 - val_loss: 3.2204 - val_accuracy: 0.3267\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.7911 - accuracy: 0.4082 - val_loss: 3.2338 - val_accuracy: 0.3235\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.7781 - accuracy: 0.4123 - val_loss: 3.2524 - val_accuracy: 0.3191\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.7653 - accuracy: 0.4145 - val_loss: 3.2737 - val_accuracy: 0.3089\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.7538 - accuracy: 0.4134 - val_loss: 3.2927 - val_accuracy: 0.3032\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.7483 - accuracy: 0.4129 - val_loss: 3.3228 - val_accuracy: 0.2942\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.7761 - accuracy: 0.4082 - val_loss: 3.3325 - val_accuracy: 0.2798\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.8923 - accuracy: 0.3688 - val_loss: 3.3557 - val_accuracy: 0.2593\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.8277 - accuracy: 0.3783 - val_loss: 3.3885 - val_accuracy: 0.2220\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.8060 - accuracy: 0.3896 - val_loss: 3.4292 - val_accuracy: 0.1660\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.7746 - accuracy: 0.3992 - val_loss: 3.4665 - val_accuracy: 0.0838\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 1.7521 - accuracy: 0.4094 - val_loss: 3.5032 - val_accuracy: 0.0338\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.7571 - accuracy: 0.4080 - val_loss: 3.5362 - val_accuracy: 0.0338\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.7449 - accuracy: 0.4091 - val_loss: 3.5657 - val_accuracy: 0.0337\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.7326 - accuracy: 0.4102 - val_loss: 3.5908 - val_accuracy: 0.0335\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.7240 - accuracy: 0.4117 - val_loss: 3.6125 - val_accuracy: 0.0334\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.7161 - accuracy: 0.4135 - val_loss: 3.6360 - val_accuracy: 0.0331\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.7089 - accuracy: 0.4172 - val_loss: 3.6626 - val_accuracy: 0.0329\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 1.6964 - accuracy: 0.4230 - val_loss: 3.6911 - val_accuracy: 0.0326\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.6854 - accuracy: 0.4275 - val_loss: 3.7220 - val_accuracy: 0.0321\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.6745 - accuracy: 0.4252 - val_loss: 3.7545 - val_accuracy: 0.0319\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.6626 - accuracy: 0.4227 - val_loss: 3.7868 - val_accuracy: 0.0319\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.6492 - accuracy: 0.4207 - val_loss: 3.8169 - val_accuracy: 0.0317\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.6352 - accuracy: 0.4206 - val_loss: 3.8463 - val_accuracy: 0.0315\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.6222 - accuracy: 0.4209 - val_loss: 3.8766 - val_accuracy: 0.0314\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.6116 - accuracy: 0.4211 - val_loss: 3.9068 - val_accuracy: 0.0312\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.6029 - accuracy: 0.4209 - val_loss: 3.9385 - val_accuracy: 0.0312\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.5964 - accuracy: 0.4217 - val_loss: 3.9724 - val_accuracy: 0.0310\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.5907 - accuracy: 0.4279 - val_loss: 4.0027 - val_accuracy: 0.0310\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.5851 - accuracy: 0.4327 - val_loss: 4.0299 - val_accuracy: 0.0310\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.5792 - accuracy: 0.4239 - val_loss: 4.0559 - val_accuracy: 0.0310\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.5731 - accuracy: 0.4233 - val_loss: 4.0820 - val_accuracy: 0.0310\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.5670 - accuracy: 0.4243 - val_loss: 4.1085 - val_accuracy: 0.0310\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 1.5610 - accuracy: 0.4256 - val_loss: 4.1342 - val_accuracy: 0.0310\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.5553 - accuracy: 0.4276 - val_loss: 4.1601 - val_accuracy: 0.0311\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.5500 - accuracy: 0.4304 - val_loss: 4.1858 - val_accuracy: 0.0311\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.5447 - accuracy: 0.4327 - val_loss: 4.2104 - val_accuracy: 0.0311\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.5396 - accuracy: 0.4336 - val_loss: 4.2347 - val_accuracy: 0.0311\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.5346 - accuracy: 0.4331 - val_loss: 4.2585 - val_accuracy: 0.0311\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.5294 - accuracy: 0.4319 - val_loss: 4.2823 - val_accuracy: 0.0311\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.5241 - accuracy: 0.4317 - val_loss: 4.3052 - val_accuracy: 0.0310\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 1.5185 - accuracy: 0.4327 - val_loss: 4.3266 - val_accuracy: 0.0310\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.5128 - accuracy: 0.4336 - val_loss: 4.3463 - val_accuracy: 0.0310\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.5067 - accuracy: 0.4351 - val_loss: 4.3657 - val_accuracy: 0.0310\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.5005 - accuracy: 0.4356 - val_loss: 4.3844 - val_accuracy: 0.0310\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.4940 - accuracy: 0.4349 - val_loss: 4.4017 - val_accuracy: 0.0310\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 1.4871 - accuracy: 0.4341 - val_loss: 4.4173 - val_accuracy: 0.0310\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.4800 - accuracy: 0.4345 - val_loss: 4.4323 - val_accuracy: 0.0309\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.4725 - accuracy: 0.4322 - val_loss: 4.4473 - val_accuracy: 0.0309\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 1.4646 - accuracy: 0.4314 - val_loss: 4.4613 - val_accuracy: 0.0309\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.4564 - accuracy: 0.4313 - val_loss: 4.4703 - val_accuracy: 0.0309\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.4478 - accuracy: 0.4313 - val_loss: 4.4725 - val_accuracy: 0.0308\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 1.4390 - accuracy: 0.4319 - val_loss: 4.4644 - val_accuracy: 0.0308\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.4301 - accuracy: 0.4329 - val_loss: 4.4439 - val_accuracy: 0.0308\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 1.4211 - accuracy: 0.4342 - val_loss: 4.4089 - val_accuracy: 0.0309\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 1.4121 - accuracy: 0.4357 - val_loss: 4.3583 - val_accuracy: 0.0309\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 1.4033 - accuracy: 0.4379 - val_loss: 4.2951 - val_accuracy: 0.0309\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.3947 - accuracy: 0.4404 - val_loss: 4.2272 - val_accuracy: 0.0310\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: 1.3864 - accuracy: 0.4436 - val_loss: 4.1647 - val_accuracy: 0.0310\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 1.3784 - accuracy: 0.4496 - val_loss: 4.1109 - val_accuracy: 0.0310\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 1.3707 - accuracy: 0.4574 - val_loss: 4.0635 - val_accuracy: 0.0310\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.3631 - accuracy: 0.4620 - val_loss: 4.0209 - val_accuracy: 0.0310\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.3556 - accuracy: 0.4588 - val_loss: 3.9828 - val_accuracy: 0.0313\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 1.3482 - accuracy: 0.4636 - val_loss: 3.9509 - val_accuracy: 0.0275\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.3406 - accuracy: 0.4686 - val_loss: 3.9274 - val_accuracy: 0.0263\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 1.3330 - accuracy: 0.4727 - val_loss: 3.9165 - val_accuracy: 0.0323\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.3253 - accuracy: 0.4765 - val_loss: 3.9263 - val_accuracy: 0.0403\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.3175 - accuracy: 0.4800 - val_loss: 3.9699 - val_accuracy: 0.0488\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.3095 - accuracy: 0.4834 - val_loss: 4.0596 - val_accuracy: 0.0580\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.3015 - accuracy: 0.4868 - val_loss: 4.2062 - val_accuracy: 0.0663\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.2934 - accuracy: 0.4906 - val_loss: 4.4168 - val_accuracy: 0.0720\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.2853 - accuracy: 0.4945 - val_loss: 4.6968 - val_accuracy: 0.0768\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.2771 - accuracy: 0.4987 - val_loss: 5.0586 - val_accuracy: 0.0821\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.2689 - accuracy: 0.5036 - val_loss: 5.5127 - val_accuracy: 0.0887\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 1.2606 - accuracy: 0.5086 - val_loss: 6.0591 - val_accuracy: 0.0980\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.2521 - accuracy: 0.5143 - val_loss: 6.6851 - val_accuracy: 0.1106\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.2432 - accuracy: 0.5204 - val_loss: 7.3773 - val_accuracy: 0.1355\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 1.2340 - accuracy: 0.5265 - val_loss: 8.1431 - val_accuracy: 0.1585\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.2243 - accuracy: 0.5325 - val_loss: 8.9851 - val_accuracy: 0.1708\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 1.2142 - accuracy: 0.5380 - val_loss: 9.9145 - val_accuracy: 0.1801\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 1.2037 - accuracy: 0.5440 - val_loss: 10.9055 - val_accuracy: 0.1890\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 1.1928 - accuracy: 0.5503 - val_loss: 11.9147 - val_accuracy: 0.1970\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.1811 - accuracy: 0.5574 - val_loss: 12.9207 - val_accuracy: 0.2043\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.1688 - accuracy: 0.5648 - val_loss: 13.8809 - val_accuracy: 0.2107\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.1557 - accuracy: 0.5721 - val_loss: 14.7283 - val_accuracy: 0.2144\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 1.1420 - accuracy: 0.5806 - val_loss: 15.4214 - val_accuracy: 0.2167\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 1.1277 - accuracy: 0.5908 - val_loss: 15.9227 - val_accuracy: 0.2176\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.1127 - accuracy: 0.6026 - val_loss: 16.2300 - val_accuracy: 0.2172\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 1.0974 - accuracy: 0.6164 - val_loss: 16.4199 - val_accuracy: 0.2157\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.0818 - accuracy: 0.6294 - val_loss: 16.2447 - val_accuracy: 0.2129\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 1.0662 - accuracy: 0.6399 - val_loss: 16.3481 - val_accuracy: 0.2113\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.0517 - accuracy: 0.6504 - val_loss: 15.4172 - val_accuracy: 0.2048\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 1.0457 - accuracy: 0.6499 - val_loss: 17.7841 - val_accuracy: 0.2138\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 1.0972 - accuracy: 0.6408 - val_loss: 13.1542 - val_accuracy: 0.1730\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 1.1354 - accuracy: 0.6022 - val_loss: 20.0312 - val_accuracy: 0.2098\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 1.0869 - accuracy: 0.6405 - val_loss: 16.6128 - val_accuracy: 0.1864\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 1.0153 - accuracy: 0.6554 - val_loss: 16.7660 - val_accuracy: 0.1855\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 1.0000 - accuracy: 0.6633 - val_loss: 17.5987 - val_accuracy: 0.1917\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.9835 - accuracy: 0.6671 - val_loss: 18.3018 - val_accuracy: 0.1972\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9657 - accuracy: 0.6700 - val_loss: 18.6334 - val_accuracy: 0.2011\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.9481 - accuracy: 0.6751 - val_loss: 18.5553 - val_accuracy: 0.2024\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.9327 - accuracy: 0.6822 - val_loss: 18.0905 - val_accuracy: 0.2009\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.9188 - accuracy: 0.6903 - val_loss: 17.5013 - val_accuracy: 0.1976\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.9052 - accuracy: 0.6984 - val_loss: 17.1160 - val_accuracy: 0.1945\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8923 - accuracy: 0.7053 - val_loss: 17.0603 - val_accuracy: 0.1925\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8801 - accuracy: 0.7105 - val_loss: 17.3357 - val_accuracy: 0.1925\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.8684 - accuracy: 0.7141 - val_loss: 17.8364 - val_accuracy: 0.1937\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.8568 - accuracy: 0.7170 - val_loss: 18.5194 - val_accuracy: 0.1963\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.8453 - accuracy: 0.7194 - val_loss: 19.1684 - val_accuracy: 0.1983\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.8340 - accuracy: 0.7230 - val_loss: 19.9083 - val_accuracy: 0.2011\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8228 - accuracy: 0.7261 - val_loss: 20.3526 - val_accuracy: 0.2019\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.8118 - accuracy: 0.7291 - val_loss: 20.9920 - val_accuracy: 0.2041\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.8010 - accuracy: 0.7332 - val_loss: 21.0515 - val_accuracy: 0.2025\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.7904 - accuracy: 0.7355 - val_loss: 21.8332 - val_accuracy: 0.2054\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.7803 - accuracy: 0.7452 - val_loss: 21.1948 - val_accuracy: 0.1995\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.7715 - accuracy: 0.7429 - val_loss: 22.7650 - val_accuracy: 0.2067\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.7646 - accuracy: 0.7547 - val_loss: 20.3157 - val_accuracy: 0.1907\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.7721 - accuracy: 0.7359 - val_loss: 24.8569 - val_accuracy: 0.2118\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.7802 - accuracy: 0.7262 - val_loss: 18.1696 - val_accuracy: 0.1709\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.8560 - accuracy: 0.6991 - val_loss: 24.6815 - val_accuracy: 0.1993\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.7280 - accuracy: 0.7594 - val_loss: 25.3480 - val_accuracy: 0.2022\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7188 - accuracy: 0.7685 - val_loss: 24.4382 - val_accuracy: 0.1958\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.7071 - accuracy: 0.7766 - val_loss: 25.2111 - val_accuracy: 0.1966\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.6975 - accuracy: 0.7808 - val_loss: 25.1316 - val_accuracy: 0.1922\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6882 - accuracy: 0.7861 - val_loss: 25.2636 - val_accuracy: 0.1905\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6797 - accuracy: 0.7893 - val_loss: 25.2567 - val_accuracy: 0.1879\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6713 - accuracy: 0.7923 - val_loss: 25.4225 - val_accuracy: 0.1861\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.6632 - accuracy: 0.7940 - val_loss: 25.5932 - val_accuracy: 0.1838\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.6550 - accuracy: 0.7966 - val_loss: 25.9616 - val_accuracy: 0.1821\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6469 - accuracy: 0.7988 - val_loss: 26.2577 - val_accuracy: 0.1800\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.6388 - accuracy: 0.8019 - val_loss: 26.7564 - val_accuracy: 0.1783\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.6308 - accuracy: 0.8047 - val_loss: 27.0256 - val_accuracy: 0.1741\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.6230 - accuracy: 0.8083 - val_loss: 27.8353 - val_accuracy: 0.1701\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.6156 - accuracy: 0.8095 - val_loss: 27.8943 - val_accuracy: 0.1596\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.6092 - accuracy: 0.8119 - val_loss: 29.5895 - val_accuracy: 0.1615\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.6057 - accuracy: 0.8021 - val_loss: 27.8986 - val_accuracy: 0.1424\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.6154 - accuracy: 0.7983 - val_loss: 32.1420 - val_accuracy: 0.1574\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.6142 - accuracy: 0.7786 - val_loss: 27.4776 - val_accuracy: 0.1260\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.6455 - accuracy: 0.7689 - val_loss: 34.4348 - val_accuracy: 0.1492\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 161ms/step - loss: 0.5999 - accuracy: 0.7850 - val_loss: 30.7652 - val_accuracy: 0.1283\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5901 - accuracy: 0.8041 - val_loss: 33.9352 - val_accuracy: 0.1378\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5650 - accuracy: 0.8077 - val_loss: 34.0443 - val_accuracy: 0.1322\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.5565 - accuracy: 0.8135 - val_loss: 34.0461 - val_accuracy: 0.1283\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5488 - accuracy: 0.8151 - val_loss: 33.5372 - val_accuracy: 0.1230\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5409 - accuracy: 0.8180 - val_loss: 33.0543 - val_accuracy: 0.1192\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.5331 - accuracy: 0.8197 - val_loss: 32.4816 - val_accuracy: 0.1157\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.5257 - accuracy: 0.8216 - val_loss: 32.0839 - val_accuracy: 0.1129\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.5187 - accuracy: 0.8230 - val_loss: 31.8697 - val_accuracy: 0.1104\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.5117 - accuracy: 0.8241 - val_loss: 31.8869 - val_accuracy: 0.1085\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.5045 - accuracy: 0.8249 - val_loss: 32.0456 - val_accuracy: 0.1069\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4973 - accuracy: 0.8257 - val_loss: 32.3603 - val_accuracy: 0.1059\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.4900 - accuracy: 0.8261 - val_loss: 32.7760 - val_accuracy: 0.1054\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4827 - accuracy: 0.8264 - val_loss: 33.2910 - val_accuracy: 0.1056\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4754 - accuracy: 0.8266 - val_loss: 33.8760 - val_accuracy: 0.1063\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.4681 - accuracy: 0.8268 - val_loss: 34.5276 - val_accuracy: 0.1079\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4608 - accuracy: 0.8272 - val_loss: 35.2247 - val_accuracy: 0.1101\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.4535 - accuracy: 0.8291 - val_loss: 35.9460 - val_accuracy: 0.1129\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.4462 - accuracy: 0.8295 - val_loss: 36.7020 - val_accuracy: 0.1168\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4391 - accuracy: 0.8285 - val_loss: 37.5036 - val_accuracy: 0.1217\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4320 - accuracy: 0.8275 - val_loss: 38.3828 - val_accuracy: 0.1280\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4251 - accuracy: 0.8269 - val_loss: 39.3086 - val_accuracy: 0.1360\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.4183 - accuracy: 0.8267 - val_loss: 40.2523 - val_accuracy: 0.1457\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4117 - accuracy: 0.8272 - val_loss: 41.1293 - val_accuracy: 0.1566\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.4053 - accuracy: 0.8277 - val_loss: 41.8722 - val_accuracy: 0.1684\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.3991 - accuracy: 0.8282 - val_loss: 42.4383 - val_accuracy: 0.1808\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3930 - accuracy: 0.8284 - val_loss: 42.8214 - val_accuracy: 0.1934\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.3870 - accuracy: 0.8288 - val_loss: 43.0234 - val_accuracy: 0.2052\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.3811 - accuracy: 0.8292 - val_loss: 43.0495 - val_accuracy: 0.2161\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.3753 - accuracy: 0.8295 - val_loss: 42.9168 - val_accuracy: 0.2258\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3697 - accuracy: 0.8298 - val_loss: 42.6249 - val_accuracy: 0.2330\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3642 - accuracy: 0.8302 - val_loss: 42.1835 - val_accuracy: 0.2374\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3588 - accuracy: 0.8305 - val_loss: 41.6140 - val_accuracy: 0.2395\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3536 - accuracy: 0.8309 - val_loss: 40.8874 - val_accuracy: 0.2389\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3486 - accuracy: 0.8312 - val_loss: 39.9998 - val_accuracy: 0.2359\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.3437 - accuracy: 0.8315 - val_loss: 38.9592 - val_accuracy: 0.2294\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.3390 - accuracy: 0.8318 - val_loss: 37.7636 - val_accuracy: 0.2193\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.3344 - accuracy: 0.8321 - val_loss: 36.4254 - val_accuracy: 0.2065\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3300 - accuracy: 0.8325 - val_loss: 34.9899 - val_accuracy: 0.1921\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3256 - accuracy: 0.8330 - val_loss: 33.4591 - val_accuracy: 0.1769\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3212 - accuracy: 0.8334 - val_loss: 31.8754 - val_accuracy: 0.1628\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.3169 - accuracy: 0.8338 - val_loss: 30.2814 - val_accuracy: 0.1497\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.3125 - accuracy: 0.8342 - val_loss: 28.6985 - val_accuracy: 0.1384\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.3081 - accuracy: 0.8345 - val_loss: 27.1465 - val_accuracy: 0.1279\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.3037 - accuracy: 0.8348 - val_loss: 25.6479 - val_accuracy: 0.1182\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2992 - accuracy: 0.8351 - val_loss: 24.2304 - val_accuracy: 0.1089\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2948 - accuracy: 0.8354 - val_loss: 22.9016 - val_accuracy: 0.1003\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2903 - accuracy: 0.8356 - val_loss: 21.6745 - val_accuracy: 0.0918\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.2859 - accuracy: 0.8358 - val_loss: 20.5364 - val_accuracy: 0.0839\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2815 - accuracy: 0.8360 - val_loss: 19.4893 - val_accuracy: 0.0760\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2773 - accuracy: 0.8362 - val_loss: 18.5209 - val_accuracy: 0.0692\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2730 - accuracy: 0.8363 - val_loss: 17.6205 - val_accuracy: 0.0634\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2689 - accuracy: 0.8366 - val_loss: 16.8103 - val_accuracy: 0.0580\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2648 - accuracy: 0.8367 - val_loss: 16.0752 - val_accuracy: 0.0533\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.2608 - accuracy: 0.8370 - val_loss: 15.4352 - val_accuracy: 0.0495\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2569 - accuracy: 0.8374 - val_loss: 14.8763 - val_accuracy: 0.0465\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.2531 - accuracy: 0.8380 - val_loss: 14.3890 - val_accuracy: 0.0442\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2493 - accuracy: 0.8389 - val_loss: 13.9746 - val_accuracy: 0.0427\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.2455 - accuracy: 0.8400 - val_loss: 13.6330 - val_accuracy: 0.0415\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.2417 - accuracy: 0.8409 - val_loss: 13.3634 - val_accuracy: 0.0407\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2380 - accuracy: 0.8418 - val_loss: 13.1551 - val_accuracy: 0.0401\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2342 - accuracy: 0.8427 - val_loss: 13.0006 - val_accuracy: 0.0398\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2304 - accuracy: 0.8437 - val_loss: 12.8879 - val_accuracy: 0.0397\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2266 - accuracy: 0.8444 - val_loss: 12.8217 - val_accuracy: 0.0401\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2229 - accuracy: 0.8448 - val_loss: 12.7893 - val_accuracy: 0.0407\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2191 - accuracy: 0.8455 - val_loss: 12.7928 - val_accuracy: 0.0414\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2154 - accuracy: 0.8461 - val_loss: 12.8237 - val_accuracy: 0.0427\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.2116 - accuracy: 0.8466 - val_loss: 12.8789 - val_accuracy: 0.0444\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2079 - accuracy: 0.8474 - val_loss: 12.9503 - val_accuracy: 0.0464\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.2042 - accuracy: 0.8481 - val_loss: 13.0281 - val_accuracy: 0.0493\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.2005 - accuracy: 0.8488 - val_loss: 13.1109 - val_accuracy: 0.0522\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1968 - accuracy: 0.8498 - val_loss: 13.2093 - val_accuracy: 0.0551\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1931 - accuracy: 0.8511 - val_loss: 13.3205 - val_accuracy: 0.0576\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1894 - accuracy: 0.8523 - val_loss: 13.4376 - val_accuracy: 0.0596\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.1856 - accuracy: 0.8535 - val_loss: 13.5626 - val_accuracy: 0.0612\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1819 - accuracy: 0.8549 - val_loss: 13.6913 - val_accuracy: 0.0625\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1782 - accuracy: 0.8562 - val_loss: 13.8264 - val_accuracy: 0.0626\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1744 - accuracy: 0.8577 - val_loss: 13.9625 - val_accuracy: 0.0618\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1707 - accuracy: 0.8592 - val_loss: 14.0978 - val_accuracy: 0.0595\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.1669 - accuracy: 0.8607 - val_loss: 14.2284 - val_accuracy: 0.0559\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.1631 - accuracy: 0.8624 - val_loss: 14.3612 - val_accuracy: 0.0516\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1593 - accuracy: 0.8640 - val_loss: 14.4998 - val_accuracy: 0.0464\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1554 - accuracy: 0.8656 - val_loss: 14.6524 - val_accuracy: 0.0413\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.1516 - accuracy: 0.8671 - val_loss: 14.8177 - val_accuracy: 0.0368\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.1478 - accuracy: 0.8687 - val_loss: 15.0055 - val_accuracy: 0.0331\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.1440 - accuracy: 0.8703 - val_loss: 15.2022 - val_accuracy: 0.0309\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1402 - accuracy: 0.8719 - val_loss: 15.4115 - val_accuracy: 0.0293\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1365 - accuracy: 0.8731 - val_loss: 15.6349 - val_accuracy: 0.0278\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1328 - accuracy: 0.8744 - val_loss: 15.8608 - val_accuracy: 0.0263\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.1292 - accuracy: 0.8758 - val_loss: 16.1002 - val_accuracy: 0.0250\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1256 - accuracy: 0.8768 - val_loss: 16.3422 - val_accuracy: 0.0236\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1220 - accuracy: 0.8776 - val_loss: 16.5964 - val_accuracy: 0.0225\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1185 - accuracy: 0.8784 - val_loss: 16.8601 - val_accuracy: 0.0214\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.1150 - accuracy: 0.8790 - val_loss: 17.1394 - val_accuracy: 0.0204\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.1115 - accuracy: 0.8798 - val_loss: 17.4296 - val_accuracy: 0.0194\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.1081 - accuracy: 0.8804 - val_loss: 17.7278 - val_accuracy: 0.0186\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.1047 - accuracy: 0.8811 - val_loss: 18.0411 - val_accuracy: 0.0176\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.1013 - accuracy: 0.8821 - val_loss: 18.3691 - val_accuracy: 0.0166\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0979 - accuracy: 0.8831 - val_loss: 18.7098 - val_accuracy: 0.0158\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0946 - accuracy: 0.8842 - val_loss: 19.0696 - val_accuracy: 0.0150\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.0912 - accuracy: 0.8852 - val_loss: 19.4464 - val_accuracy: 0.0142\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0879 - accuracy: 0.8862 - val_loss: 19.8431 - val_accuracy: 0.0134\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.0847 - accuracy: 0.8870 - val_loss: 20.2545 - val_accuracy: 0.0127\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.0814 - accuracy: 0.8877 - val_loss: 20.7031 - val_accuracy: 0.0121\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.0782 - accuracy: 0.8884 - val_loss: 21.1807 - val_accuracy: 0.0116\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.0750 - accuracy: 0.8890 - val_loss: 21.6973 - val_accuracy: 0.0111\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0718 - accuracy: 0.8895 - val_loss: 22.2491 - val_accuracy: 0.0107\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.0687 - accuracy: 0.8899 - val_loss: 22.8338 - val_accuracy: 0.0105\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.0656 - accuracy: 0.8902 - val_loss: 23.4507 - val_accuracy: 0.0103\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0625 - accuracy: 0.8905 - val_loss: 24.0914 - val_accuracy: 0.0102\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.0594 - accuracy: 0.8907 - val_loss: 24.7477 - val_accuracy: 0.0102\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0564 - accuracy: 0.8908 - val_loss: 25.4050 - val_accuracy: 0.0101\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: 0.0534 - accuracy: 0.8908 - val_loss: 26.0695 - val_accuracy: 0.0101\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0504 - accuracy: 0.8908 - val_loss: 26.7042 - val_accuracy: 0.0102\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.0475 - accuracy: 0.8909 - val_loss: 27.3149 - val_accuracy: 0.0102\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.0446 - accuracy: 0.8909 - val_loss: 27.8475 - val_accuracy: 0.0103\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0417 - accuracy: 0.8911 - val_loss: 28.3742 - val_accuracy: 0.0103\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0388 - accuracy: 0.8909 - val_loss: 28.7994 - val_accuracy: 0.0103\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.0360 - accuracy: 0.8912 - val_loss: 29.2682 - val_accuracy: 0.0104\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: 0.0334 - accuracy: 0.8909 - val_loss: 29.5351 - val_accuracy: 0.0104\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.0308 - accuracy: 0.8914 - val_loss: 29.9659 - val_accuracy: 0.0106\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.0293 - accuracy: 0.8904 - val_loss: 29.9537 - val_accuracy: 0.0104\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0279 - accuracy: 0.8906 - val_loss: 30.5148 - val_accuracy: 0.0108\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0342 - accuracy: 0.8878 - val_loss: 29.9850 - val_accuracy: 0.0103\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0397 - accuracy: 0.8876 - val_loss: 30.7420 - val_accuracy: 0.0110\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: 0.0759 - accuracy: 0.8784 - val_loss: 29.3990 - val_accuracy: 0.0099\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.0249 - accuracy: 0.8911 - val_loss: 30.9498 - val_accuracy: 0.0106\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: 0.0133 - accuracy: 0.8916 - val_loss: 30.6850 - val_accuracy: 0.0103\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: 0.0100 - accuracy: 0.8940 - val_loss: 30.7165 - val_accuracy: 0.0104\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.0054 - accuracy: 0.8938 - val_loss: 30.3818 - val_accuracy: 0.0102\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.0010 - accuracy: 0.8960 - val_loss: 30.3659 - val_accuracy: 0.0104\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.0025 - accuracy: 0.8968 - val_loss: 30.1799 - val_accuracy: 0.0105\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.0057 - accuracy: 0.8983 - val_loss: 29.9523 - val_accuracy: 0.0106\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.0088 - accuracy: 0.8997 - val_loss: 29.6490 - val_accuracy: 0.0107\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.0119 - accuracy: 0.9011 - val_loss: 29.3501 - val_accuracy: 0.0107\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.0149 - accuracy: 0.9024 - val_loss: 29.1031 - val_accuracy: 0.0110\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.0180 - accuracy: 0.9034 - val_loss: 28.9284 - val_accuracy: 0.0111\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.0211 - accuracy: 0.9044 - val_loss: 28.8123 - val_accuracy: 0.0114\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.0242 - accuracy: 0.9052 - val_loss: 28.7262 - val_accuracy: 0.0117\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.0272 - accuracy: 0.9059 - val_loss: 28.6579 - val_accuracy: 0.0120\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.0302 - accuracy: 0.9065 - val_loss: 28.5970 - val_accuracy: 0.0125\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.0331 - accuracy: 0.9071 - val_loss: 28.5335 - val_accuracy: 0.0128\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.0360 - accuracy: 0.9077 - val_loss: 28.4802 - val_accuracy: 0.0131\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.0389 - accuracy: 0.9081 - val_loss: 28.4311 - val_accuracy: 0.0134\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.0417 - accuracy: 0.9086 - val_loss: 28.4047 - val_accuracy: 0.0137\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.0445 - accuracy: 0.9091 - val_loss: 28.4001 - val_accuracy: 0.0139\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.0473 - accuracy: 0.9095 - val_loss: 28.4273 - val_accuracy: 0.0142\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.0501 - accuracy: 0.9099 - val_loss: 28.4874 - val_accuracy: 0.0146\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: -0.0530 - accuracy: 0.9106 - val_loss: 28.5612 - val_accuracy: 0.0150\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.0558 - accuracy: 0.9121 - val_loss: 28.6274 - val_accuracy: 0.0154\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.0586 - accuracy: 0.9131 - val_loss: 28.6632 - val_accuracy: 0.0158\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: -0.0614 - accuracy: 0.9138 - val_loss: 28.6557 - val_accuracy: 0.0163\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.0643 - accuracy: 0.9144 - val_loss: 28.5997 - val_accuracy: 0.0167\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.0671 - accuracy: 0.9148 - val_loss: 28.4821 - val_accuracy: 0.0173\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.0700 - accuracy: 0.9151 - val_loss: 28.3002 - val_accuracy: 0.0180\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.0729 - accuracy: 0.9155 - val_loss: 28.0394 - val_accuracy: 0.0187\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 158ms/step - loss: -0.0759 - accuracy: 0.9159 - val_loss: 27.7023 - val_accuracy: 0.0195\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.0789 - accuracy: 0.9163 - val_loss: 27.2942 - val_accuracy: 0.0203\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.0819 - accuracy: 0.9167 - val_loss: 26.8311 - val_accuracy: 0.0211\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.0849 - accuracy: 0.9171 - val_loss: 26.3279 - val_accuracy: 0.0219\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.0879 - accuracy: 0.9177 - val_loss: 25.7971 - val_accuracy: 0.0228\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.0910 - accuracy: 0.9182 - val_loss: 25.2404 - val_accuracy: 0.0238\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.0941 - accuracy: 0.9184 - val_loss: 24.6669 - val_accuracy: 0.0246\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.0972 - accuracy: 0.9188 - val_loss: 24.0781 - val_accuracy: 0.0253\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.1003 - accuracy: 0.9192 - val_loss: 23.4903 - val_accuracy: 0.0259\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.1034 - accuracy: 0.9198 - val_loss: 22.8947 - val_accuracy: 0.0266\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: -0.1065 - accuracy: 0.9207 - val_loss: 22.2936 - val_accuracy: 0.0271\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.1096 - accuracy: 0.9219 - val_loss: 21.6825 - val_accuracy: 0.0278\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.1127 - accuracy: 0.9234 - val_loss: 21.0624 - val_accuracy: 0.0283\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.1158 - accuracy: 0.9246 - val_loss: 20.4350 - val_accuracy: 0.0288\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.1189 - accuracy: 0.9257 - val_loss: 19.7915 - val_accuracy: 0.0292\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.1220 - accuracy: 0.9264 - val_loss: 19.1329 - val_accuracy: 0.0300\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: -0.1251 - accuracy: 0.9271 - val_loss: 18.4540 - val_accuracy: 0.0316\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.1282 - accuracy: 0.9279 - val_loss: 17.7544 - val_accuracy: 0.0345\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: -0.1313 - accuracy: 0.9284 - val_loss: 17.0510 - val_accuracy: 0.0388\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.1344 - accuracy: 0.9289 - val_loss: 16.3434 - val_accuracy: 0.0444\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.1374 - accuracy: 0.9294 - val_loss: 15.6384 - val_accuracy: 0.0495\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.1405 - accuracy: 0.9299 - val_loss: 14.9355 - val_accuracy: 0.0535\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: -0.1435 - accuracy: 0.9302 - val_loss: 14.2537 - val_accuracy: 0.0566\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: -0.1466 - accuracy: 0.9307 - val_loss: 13.6071 - val_accuracy: 0.0596\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.1497 - accuracy: 0.9311 - val_loss: 12.9996 - val_accuracy: 0.0624\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.1527 - accuracy: 0.9316 - val_loss: 12.4214 - val_accuracy: 0.0652\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.1558 - accuracy: 0.9321 - val_loss: 11.8680 - val_accuracy: 0.0684\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.1589 - accuracy: 0.9326 - val_loss: 11.3469 - val_accuracy: 0.0751\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.1620 - accuracy: 0.9331 - val_loss: 10.8867 - val_accuracy: 0.0899\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.1651 - accuracy: 0.9336 - val_loss: 10.5015 - val_accuracy: 0.1082\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.1682 - accuracy: 0.9341 - val_loss: 10.1948 - val_accuracy: 0.1234\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: -0.1714 - accuracy: 0.9347 - val_loss: 9.9458 - val_accuracy: 0.1365\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.1746 - accuracy: 0.9354 - val_loss: 9.7434 - val_accuracy: 0.1508\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.1778 - accuracy: 0.9360 - val_loss: 9.5907 - val_accuracy: 0.1665\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.1810 - accuracy: 0.9365 - val_loss: 9.4844 - val_accuracy: 0.1831\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.1843 - accuracy: 0.9371 - val_loss: 9.4271 - val_accuracy: 0.1972\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.1876 - accuracy: 0.9375 - val_loss: 9.4123 - val_accuracy: 0.2093\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.1909 - accuracy: 0.9378 - val_loss: 9.4296 - val_accuracy: 0.2192\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.1943 - accuracy: 0.9382 - val_loss: 9.4682 - val_accuracy: 0.2273\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.1976 - accuracy: 0.9385 - val_loss: 9.5201 - val_accuracy: 0.2346\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.2010 - accuracy: 0.9388 - val_loss: 9.5736 - val_accuracy: 0.2407\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.2044 - accuracy: 0.9392 - val_loss: 9.6272 - val_accuracy: 0.2457\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.2078 - accuracy: 0.9396 - val_loss: 9.6722 - val_accuracy: 0.2498\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.2112 - accuracy: 0.9400 - val_loss: 9.7017 - val_accuracy: 0.2525\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: -0.2146 - accuracy: 0.9403 - val_loss: 9.7214 - val_accuracy: 0.2546\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.2181 - accuracy: 0.9407 - val_loss: 9.7156 - val_accuracy: 0.2560\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.2215 - accuracy: 0.9411 - val_loss: 9.6927 - val_accuracy: 0.2569\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.2250 - accuracy: 0.9416 - val_loss: 9.6471 - val_accuracy: 0.2577\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.2285 - accuracy: 0.9422 - val_loss: 9.5880 - val_accuracy: 0.2580\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.2320 - accuracy: 0.9428 - val_loss: 9.5129 - val_accuracy: 0.2581\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.2355 - accuracy: 0.9433 - val_loss: 9.4254 - val_accuracy: 0.2582\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.2391 - accuracy: 0.9439 - val_loss: 9.3266 - val_accuracy: 0.2581\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.2426 - accuracy: 0.9444 - val_loss: 9.2156 - val_accuracy: 0.2585\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: -0.2462 - accuracy: 0.9450 - val_loss: 9.1003 - val_accuracy: 0.2588\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.2497 - accuracy: 0.9455 - val_loss: 8.9773 - val_accuracy: 0.2590\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.2533 - accuracy: 0.9460 - val_loss: 8.8580 - val_accuracy: 0.2594\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.2569 - accuracy: 0.9465 - val_loss: 8.7395 - val_accuracy: 0.2598\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.2605 - accuracy: 0.9469 - val_loss: 8.6258 - val_accuracy: 0.2602\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.2640 - accuracy: 0.9474 - val_loss: 8.5161 - val_accuracy: 0.2611\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.2676 - accuracy: 0.9478 - val_loss: 8.4209 - val_accuracy: 0.2623\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.2711 - accuracy: 0.9483 - val_loss: 8.3374 - val_accuracy: 0.2634\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.2746 - accuracy: 0.9487 - val_loss: 8.2720 - val_accuracy: 0.2643\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.2781 - accuracy: 0.9490 - val_loss: 8.2165 - val_accuracy: 0.2649\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.2815 - accuracy: 0.9494 - val_loss: 8.1789 - val_accuracy: 0.2645\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.2850 - accuracy: 0.9498 - val_loss: 8.1524 - val_accuracy: 0.2637\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.2884 - accuracy: 0.9502 - val_loss: 8.1409 - val_accuracy: 0.2639\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.2918 - accuracy: 0.9506 - val_loss: 8.1392 - val_accuracy: 0.2646\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.2952 - accuracy: 0.9510 - val_loss: 8.1490 - val_accuracy: 0.2655\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.2985 - accuracy: 0.9514 - val_loss: 8.1690 - val_accuracy: 0.2665\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.3019 - accuracy: 0.9518 - val_loss: 8.1967 - val_accuracy: 0.2674\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.3052 - accuracy: 0.9522 - val_loss: 8.2320 - val_accuracy: 0.2685\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.3086 - accuracy: 0.9526 - val_loss: 8.2711 - val_accuracy: 0.2695\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.3118 - accuracy: 0.9529 - val_loss: 8.3151 - val_accuracy: 0.2709\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.3151 - accuracy: 0.9533 - val_loss: 8.3589 - val_accuracy: 0.2723\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.3184 - accuracy: 0.9538 - val_loss: 8.4033 - val_accuracy: 0.2738\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.3216 - accuracy: 0.9543 - val_loss: 8.4475 - val_accuracy: 0.2754\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.3248 - accuracy: 0.9548 - val_loss: 8.4897 - val_accuracy: 0.2772\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.3279 - accuracy: 0.9552 - val_loss: 8.5285 - val_accuracy: 0.2790\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.3311 - accuracy: 0.9556 - val_loss: 8.5645 - val_accuracy: 0.2807\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.3341 - accuracy: 0.9561 - val_loss: 8.5978 - val_accuracy: 0.2825\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.3372 - accuracy: 0.9566 - val_loss: 8.6243 - val_accuracy: 0.2843\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: -0.3402 - accuracy: 0.9571 - val_loss: 8.6503 - val_accuracy: 0.2862\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.3432 - accuracy: 0.9576 - val_loss: 8.6695 - val_accuracy: 0.2879\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.3461 - accuracy: 0.9581 - val_loss: 8.6867 - val_accuracy: 0.2896\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.3490 - accuracy: 0.9585 - val_loss: 8.7000 - val_accuracy: 0.2912\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.3519 - accuracy: 0.9589 - val_loss: 8.7100 - val_accuracy: 0.2926\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.3548 - accuracy: 0.9592 - val_loss: 8.7144 - val_accuracy: 0.2939\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.3576 - accuracy: 0.9596 - val_loss: 8.7199 - val_accuracy: 0.2951\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.3604 - accuracy: 0.9599 - val_loss: 8.7199 - val_accuracy: 0.2965\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.3632 - accuracy: 0.9603 - val_loss: 8.7185 - val_accuracy: 0.2979\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.3660 - accuracy: 0.9607 - val_loss: 8.7116 - val_accuracy: 0.2990\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.3687 - accuracy: 0.9612 - val_loss: 8.7034 - val_accuracy: 0.3004\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.3715 - accuracy: 0.9617 - val_loss: 8.6867 - val_accuracy: 0.3014\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.3743 - accuracy: 0.9621 - val_loss: 8.6737 - val_accuracy: 0.3027\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.3771 - accuracy: 0.9626 - val_loss: 8.6520 - val_accuracy: 0.3035\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.3799 - accuracy: 0.9631 - val_loss: 8.6350 - val_accuracy: 0.3047\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.3827 - accuracy: 0.9635 - val_loss: 8.6110 - val_accuracy: 0.3053\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.3856 - accuracy: 0.9639 - val_loss: 8.5924 - val_accuracy: 0.3061\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.3884 - accuracy: 0.9643 - val_loss: 8.5676 - val_accuracy: 0.3064\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.3913 - accuracy: 0.9648 - val_loss: 8.5502 - val_accuracy: 0.3067\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.3941 - accuracy: 0.9651 - val_loss: 8.5293 - val_accuracy: 0.3069\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.3969 - accuracy: 0.9655 - val_loss: 8.5132 - val_accuracy: 0.3069\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.3998 - accuracy: 0.9658 - val_loss: 8.4961 - val_accuracy: 0.3066\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.4026 - accuracy: 0.9661 - val_loss: 8.4857 - val_accuracy: 0.3063\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.4055 - accuracy: 0.9664 - val_loss: 8.4749 - val_accuracy: 0.3056\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.4084 - accuracy: 0.9667 - val_loss: 8.4717 - val_accuracy: 0.3049\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.4112 - accuracy: 0.9670 - val_loss: 8.4705 - val_accuracy: 0.3040\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.4141 - accuracy: 0.9674 - val_loss: 8.4788 - val_accuracy: 0.3032\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.4170 - accuracy: 0.9678 - val_loss: 8.4905 - val_accuracy: 0.3023\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.4198 - accuracy: 0.9682 - val_loss: 8.5102 - val_accuracy: 0.3012\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.4227 - accuracy: 0.9686 - val_loss: 8.5338 - val_accuracy: 0.2997\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.4255 - accuracy: 0.9691 - val_loss: 8.5623 - val_accuracy: 0.2982\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.4284 - accuracy: 0.9696 - val_loss: 8.5958 - val_accuracy: 0.2962\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.4312 - accuracy: 0.9701 - val_loss: 8.6338 - val_accuracy: 0.2949\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.4340 - accuracy: 0.9707 - val_loss: 8.6775 - val_accuracy: 0.2927\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.4369 - accuracy: 0.9711 - val_loss: 8.7241 - val_accuracy: 0.2910\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.4397 - accuracy: 0.9716 - val_loss: 8.7785 - val_accuracy: 0.2879\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.4425 - accuracy: 0.9720 - val_loss: 8.8328 - val_accuracy: 0.2866\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.4452 - accuracy: 0.9725 - val_loss: 8.8950 - val_accuracy: 0.2849\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.4480 - accuracy: 0.9728 - val_loss: 8.9538 - val_accuracy: 0.2843\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.4507 - accuracy: 0.9732 - val_loss: 9.0193 - val_accuracy: 0.2827\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.4534 - accuracy: 0.9735 - val_loss: 9.0774 - val_accuracy: 0.2826\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: -0.4560 - accuracy: 0.9739 - val_loss: 9.1446 - val_accuracy: 0.2819\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.4586 - accuracy: 0.9741 - val_loss: 9.1986 - val_accuracy: 0.2826\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.4612 - accuracy: 0.9745 - val_loss: 9.2631 - val_accuracy: 0.2824\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.4637 - accuracy: 0.9746 - val_loss: 9.3120 - val_accuracy: 0.2832\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.4662 - accuracy: 0.9750 - val_loss: 9.3724 - val_accuracy: 0.2838\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.4686 - accuracy: 0.9750 - val_loss: 9.4151 - val_accuracy: 0.2849\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.4709 - accuracy: 0.9754 - val_loss: 9.4720 - val_accuracy: 0.2856\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.4733 - accuracy: 0.9754 - val_loss: 9.5061 - val_accuracy: 0.2870\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.4755 - accuracy: 0.9758 - val_loss: 9.5573 - val_accuracy: 0.2878\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.4777 - accuracy: 0.9756 - val_loss: 9.5809 - val_accuracy: 0.2893\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.4799 - accuracy: 0.9761 - val_loss: 9.6259 - val_accuracy: 0.2898\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 159ms/step - loss: -0.4820 - accuracy: 0.9758 - val_loss: 9.6355 - val_accuracy: 0.2915\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.4840 - accuracy: 0.9765 - val_loss: 9.6739 - val_accuracy: 0.2923\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: -0.4860 - accuracy: 0.9760 - val_loss: 9.6673 - val_accuracy: 0.2945\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.4878 - accuracy: 0.9768 - val_loss: 9.7005 - val_accuracy: 0.2948\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: -0.4897 - accuracy: 0.9761 - val_loss: 9.6841 - val_accuracy: 0.2976\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.4910 - accuracy: 0.9771 - val_loss: 9.7168 - val_accuracy: 0.2976\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.4929 - accuracy: 0.9763 - val_loss: 9.6967 - val_accuracy: 0.3006\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.4939 - accuracy: 0.9774 - val_loss: 9.7334 - val_accuracy: 0.3001\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.4958 - accuracy: 0.9765 - val_loss: 9.7153 - val_accuracy: 0.3028\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.4966 - accuracy: 0.9777 - val_loss: 9.7583 - val_accuracy: 0.3021\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.4991 - accuracy: 0.9769 - val_loss: 9.7491 - val_accuracy: 0.3050\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.5003 - accuracy: 0.9781 - val_loss: 9.7927 - val_accuracy: 0.3041\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.5033 - accuracy: 0.9774 - val_loss: 9.7867 - val_accuracy: 0.3072\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.5054 - accuracy: 0.9786 - val_loss: 9.8247 - val_accuracy: 0.3063\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.5086 - accuracy: 0.9782 - val_loss: 9.8173 - val_accuracy: 0.3094\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.5111 - accuracy: 0.9793 - val_loss: 9.8475 - val_accuracy: 0.3088\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.5141 - accuracy: 0.9790 - val_loss: 9.8356 - val_accuracy: 0.3117\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.5166 - accuracy: 0.9799 - val_loss: 9.8554 - val_accuracy: 0.3112\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.5192 - accuracy: 0.9798 - val_loss: 9.8376 - val_accuracy: 0.3142\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.5214 - accuracy: 0.9804 - val_loss: 9.8489 - val_accuracy: 0.3137\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.5238 - accuracy: 0.9804 - val_loss: 9.8278 - val_accuracy: 0.3166\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.5258 - accuracy: 0.9808 - val_loss: 9.8343 - val_accuracy: 0.3164\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.5279 - accuracy: 0.9809 - val_loss: 9.8098 - val_accuracy: 0.3190\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.5298 - accuracy: 0.9810 - val_loss: 9.8117 - val_accuracy: 0.3190\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.5319 - accuracy: 0.9814 - val_loss: 9.7834 - val_accuracy: 0.3215\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.5337 - accuracy: 0.9811 - val_loss: 9.7854 - val_accuracy: 0.3215\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: -0.5357 - accuracy: 0.9817 - val_loss: 9.7568 - val_accuracy: 0.3240\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.5375 - accuracy: 0.9814 - val_loss: 9.7587 - val_accuracy: 0.3240\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.5396 - accuracy: 0.9823 - val_loss: 9.7311 - val_accuracy: 0.3266\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.5415 - accuracy: 0.9816 - val_loss: 9.7355 - val_accuracy: 0.3265\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.5435 - accuracy: 0.9829 - val_loss: 9.7066 - val_accuracy: 0.3289\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: -0.5454 - accuracy: 0.9823 - val_loss: 9.7126 - val_accuracy: 0.3289\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.5474 - accuracy: 0.9835 - val_loss: 9.6890 - val_accuracy: 0.3313\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.5493 - accuracy: 0.9832 - val_loss: 9.6984 - val_accuracy: 0.3316\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.5513 - accuracy: 0.9838 - val_loss: 9.6784 - val_accuracy: 0.3338\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.5531 - accuracy: 0.9839 - val_loss: 9.6915 - val_accuracy: 0.3336\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.5550 - accuracy: 0.9840 - val_loss: 9.6721 - val_accuracy: 0.3357\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.5568 - accuracy: 0.9842 - val_loss: 9.6890 - val_accuracy: 0.3355\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.5587 - accuracy: 0.9842 - val_loss: 9.6692 - val_accuracy: 0.3374\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.5604 - accuracy: 0.9844 - val_loss: 9.6905 - val_accuracy: 0.3372\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.5622 - accuracy: 0.9845 - val_loss: 9.6671 - val_accuracy: 0.3390\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.5639 - accuracy: 0.9847 - val_loss: 9.6895 - val_accuracy: 0.3385\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.5657 - accuracy: 0.9847 - val_loss: 9.6609 - val_accuracy: 0.3401\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.5673 - accuracy: 0.9849 - val_loss: 9.6833 - val_accuracy: 0.3392\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.5691 - accuracy: 0.9848 - val_loss: 9.6495 - val_accuracy: 0.3405\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.5707 - accuracy: 0.9851 - val_loss: 9.6727 - val_accuracy: 0.3395\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.5724 - accuracy: 0.9850 - val_loss: 9.6334 - val_accuracy: 0.3410\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.5740 - accuracy: 0.9853 - val_loss: 9.6531 - val_accuracy: 0.3401\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.5758 - accuracy: 0.9852 - val_loss: 9.6122 - val_accuracy: 0.3411\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.5773 - accuracy: 0.9855 - val_loss: 9.6302 - val_accuracy: 0.3406\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.5790 - accuracy: 0.9854 - val_loss: 9.5885 - val_accuracy: 0.3415\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.5806 - accuracy: 0.9856 - val_loss: 9.6047 - val_accuracy: 0.3411\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.5823 - accuracy: 0.9857 - val_loss: 9.5617 - val_accuracy: 0.3419\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.5838 - accuracy: 0.9861 - val_loss: 9.5751 - val_accuracy: 0.3417\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.5854 - accuracy: 0.9862 - val_loss: 9.5318 - val_accuracy: 0.3425\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.5869 - accuracy: 0.9865 - val_loss: 9.5429 - val_accuracy: 0.3425\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.5884 - accuracy: 0.9866 - val_loss: 9.4974 - val_accuracy: 0.3432\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.5898 - accuracy: 0.9867 - val_loss: 9.5063 - val_accuracy: 0.3431\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.5913 - accuracy: 0.9869 - val_loss: 9.4584 - val_accuracy: 0.3437\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.5927 - accuracy: 0.9870 - val_loss: 9.4646 - val_accuracy: 0.3437\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.5941 - accuracy: 0.9871 - val_loss: 9.4154 - val_accuracy: 0.3441\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.5955 - accuracy: 0.9872 - val_loss: 9.4199 - val_accuracy: 0.3441\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.5969 - accuracy: 0.9873 - val_loss: 9.3707 - val_accuracy: 0.3447\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.5982 - accuracy: 0.9874 - val_loss: 9.3760 - val_accuracy: 0.3446\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.5995 - accuracy: 0.9874 - val_loss: 9.3245 - val_accuracy: 0.3450\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6008 - accuracy: 0.9875 - val_loss: 9.3306 - val_accuracy: 0.3449\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6021 - accuracy: 0.9875 - val_loss: 9.2789 - val_accuracy: 0.3453\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.6034 - accuracy: 0.9876 - val_loss: 9.2863 - val_accuracy: 0.3451\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6047 - accuracy: 0.9875 - val_loss: 9.2352 - val_accuracy: 0.3455\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6059 - accuracy: 0.9877 - val_loss: 9.2443 - val_accuracy: 0.3453\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6073 - accuracy: 0.9877 - val_loss: 9.1949 - val_accuracy: 0.3455\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 157ms/step - loss: -0.6085 - accuracy: 0.9878 - val_loss: 9.2049 - val_accuracy: 0.3454\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6098 - accuracy: 0.9877 - val_loss: 9.1589 - val_accuracy: 0.3456\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6111 - accuracy: 0.9879 - val_loss: 9.1676 - val_accuracy: 0.3459\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.6124 - accuracy: 0.9878 - val_loss: 9.1265 - val_accuracy: 0.3460\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.6137 - accuracy: 0.9880 - val_loss: 9.1340 - val_accuracy: 0.3458\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6150 - accuracy: 0.9880 - val_loss: 9.0981 - val_accuracy: 0.3461\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6163 - accuracy: 0.9881 - val_loss: 9.1041 - val_accuracy: 0.3462\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6176 - accuracy: 0.9881 - val_loss: 9.0735 - val_accuracy: 0.3469\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6189 - accuracy: 0.9882 - val_loss: 9.0789 - val_accuracy: 0.3468\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.6202 - accuracy: 0.9882 - val_loss: 9.0558 - val_accuracy: 0.3476\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6215 - accuracy: 0.9883 - val_loss: 9.0635 - val_accuracy: 0.3476\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.6228 - accuracy: 0.9884 - val_loss: 9.0483 - val_accuracy: 0.3486\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.6241 - accuracy: 0.9885 - val_loss: 9.0577 - val_accuracy: 0.3487\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6253 - accuracy: 0.9885 - val_loss: 9.0517 - val_accuracy: 0.3490\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6266 - accuracy: 0.9886 - val_loss: 9.0649 - val_accuracy: 0.3490\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.6278 - accuracy: 0.9886 - val_loss: 9.0681 - val_accuracy: 0.3490\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6290 - accuracy: 0.9887 - val_loss: 9.0872 - val_accuracy: 0.3487\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6302 - accuracy: 0.9888 - val_loss: 9.0996 - val_accuracy: 0.3488\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6314 - accuracy: 0.9888 - val_loss: 9.1239 - val_accuracy: 0.3484\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.6326 - accuracy: 0.9889 - val_loss: 9.1445 - val_accuracy: 0.3487\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6337 - accuracy: 0.9889 - val_loss: 9.1727 - val_accuracy: 0.3486\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6348 - accuracy: 0.9891 - val_loss: 9.2014 - val_accuracy: 0.3485\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6359 - accuracy: 0.9891 - val_loss: 9.2328 - val_accuracy: 0.3482\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6370 - accuracy: 0.9892 - val_loss: 9.2674 - val_accuracy: 0.3474\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6380 - accuracy: 0.9893 - val_loss: 9.3023 - val_accuracy: 0.3467\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.6390 - accuracy: 0.9893 - val_loss: 9.3438 - val_accuracy: 0.3457\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: -0.6400 - accuracy: 0.9893 - val_loss: 9.3830 - val_accuracy: 0.3448\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.6410 - accuracy: 0.9894 - val_loss: 9.4314 - val_accuracy: 0.3437\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.6419 - accuracy: 0.9895 - val_loss: 9.4746 - val_accuracy: 0.3427\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.6428 - accuracy: 0.9895 - val_loss: 9.5275 - val_accuracy: 0.3410\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6437 - accuracy: 0.9896 - val_loss: 9.5742 - val_accuracy: 0.3395\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6446 - accuracy: 0.9896 - val_loss: 9.6315 - val_accuracy: 0.3372\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.6455 - accuracy: 0.9898 - val_loss: 9.6830 - val_accuracy: 0.3352\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6463 - accuracy: 0.9897 - val_loss: 9.7472 - val_accuracy: 0.3321\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6471 - accuracy: 0.9898 - val_loss: 9.8074 - val_accuracy: 0.3294\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6479 - accuracy: 0.9898 - val_loss: 9.8819 - val_accuracy: 0.3262\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6487 - accuracy: 0.9899 - val_loss: 9.9525 - val_accuracy: 0.3239\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6495 - accuracy: 0.9900 - val_loss: 10.0356 - val_accuracy: 0.3208\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6503 - accuracy: 0.9900 - val_loss: 10.1143 - val_accuracy: 0.3183\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6511 - accuracy: 0.9901 - val_loss: 10.2024 - val_accuracy: 0.3158\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.6518 - accuracy: 0.9901 - val_loss: 10.2852 - val_accuracy: 0.3138\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.6526 - accuracy: 0.9902 - val_loss: 10.3740 - val_accuracy: 0.3122\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.6533 - accuracy: 0.9902 - val_loss: 10.4581 - val_accuracy: 0.3107\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6540 - accuracy: 0.9903 - val_loss: 10.5446 - val_accuracy: 0.3095\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.6547 - accuracy: 0.9903 - val_loss: 10.6269 - val_accuracy: 0.3085\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.6554 - accuracy: 0.9903 - val_loss: 10.7084 - val_accuracy: 0.3077\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.6561 - accuracy: 0.9904 - val_loss: 10.7859 - val_accuracy: 0.3073\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.6568 - accuracy: 0.9904 - val_loss: 10.8614 - val_accuracy: 0.3067\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6575 - accuracy: 0.9904 - val_loss: 10.9345 - val_accuracy: 0.3069\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.6582 - accuracy: 0.9905 - val_loss: 11.0025 - val_accuracy: 0.3070\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6588 - accuracy: 0.9905 - val_loss: 11.0667 - val_accuracy: 0.3074\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6594 - accuracy: 0.9906 - val_loss: 11.1259 - val_accuracy: 0.3080\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.6601 - accuracy: 0.9906 - val_loss: 11.1805 - val_accuracy: 0.3086\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6607 - accuracy: 0.9907 - val_loss: 11.2310 - val_accuracy: 0.3090\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6613 - accuracy: 0.9908 - val_loss: 11.2768 - val_accuracy: 0.3094\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.6619 - accuracy: 0.9908 - val_loss: 11.3165 - val_accuracy: 0.3098\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6625 - accuracy: 0.9909 - val_loss: 11.3510 - val_accuracy: 0.3101\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.6631 - accuracy: 0.9910 - val_loss: 11.3798 - val_accuracy: 0.3103\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6637 - accuracy: 0.9911 - val_loss: 11.4044 - val_accuracy: 0.3108\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6642 - accuracy: 0.9911 - val_loss: 11.4234 - val_accuracy: 0.3113\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6648 - accuracy: 0.9911 - val_loss: 11.4378 - val_accuracy: 0.3117\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.6653 - accuracy: 0.9912 - val_loss: 11.4482 - val_accuracy: 0.3115\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6659 - accuracy: 0.9912 - val_loss: 11.4544 - val_accuracy: 0.3107\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6664 - accuracy: 0.9913 - val_loss: 11.4571 - val_accuracy: 0.3100\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.6669 - accuracy: 0.9914 - val_loss: 11.4584 - val_accuracy: 0.3090\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6675 - accuracy: 0.9914 - val_loss: 11.4578 - val_accuracy: 0.3079\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6680 - accuracy: 0.9914 - val_loss: 11.4566 - val_accuracy: 0.3070\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6685 - accuracy: 0.9915 - val_loss: 11.4553 - val_accuracy: 0.3062\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6690 - accuracy: 0.9916 - val_loss: 11.4533 - val_accuracy: 0.3057\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6695 - accuracy: 0.9916 - val_loss: 11.4526 - val_accuracy: 0.3054\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.6700 - accuracy: 0.9916 - val_loss: 11.4547 - val_accuracy: 0.3056\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6704 - accuracy: 0.9916 - val_loss: 11.4602 - val_accuracy: 0.3060\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6709 - accuracy: 0.9917 - val_loss: 11.4694 - val_accuracy: 0.3060\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6714 - accuracy: 0.9917 - val_loss: 11.4827 - val_accuracy: 0.3060\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.6718 - accuracy: 0.9917 - val_loss: 11.5003 - val_accuracy: 0.3063\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6723 - accuracy: 0.9917 - val_loss: 11.5204 - val_accuracy: 0.3068\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6727 - accuracy: 0.9918 - val_loss: 11.5449 - val_accuracy: 0.3070\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6731 - accuracy: 0.9918 - val_loss: 11.5724 - val_accuracy: 0.3072\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6736 - accuracy: 0.9918 - val_loss: 11.6023 - val_accuracy: 0.3074\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: -0.6740 - accuracy: 0.9919 - val_loss: 11.6343 - val_accuracy: 0.3073\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6744 - accuracy: 0.9919 - val_loss: 11.6674 - val_accuracy: 0.3067\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6748 - accuracy: 0.9919 - val_loss: 11.7027 - val_accuracy: 0.3058\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6752 - accuracy: 0.9919 - val_loss: 11.7380 - val_accuracy: 0.3055\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: -0.6756 - accuracy: 0.9920 - val_loss: 11.7748 - val_accuracy: 0.3047\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6760 - accuracy: 0.9920 - val_loss: 11.8113 - val_accuracy: 0.3041\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6764 - accuracy: 0.9921 - val_loss: 11.8476 - val_accuracy: 0.3039\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6768 - accuracy: 0.9921 - val_loss: 11.8830 - val_accuracy: 0.3039\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6772 - accuracy: 0.9922 - val_loss: 11.9180 - val_accuracy: 0.3039\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.6776 - accuracy: 0.9922 - val_loss: 11.9522 - val_accuracy: 0.3041\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6780 - accuracy: 0.9923 - val_loss: 11.9864 - val_accuracy: 0.3042\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6783 - accuracy: 0.9923 - val_loss: 12.0190 - val_accuracy: 0.3043\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6787 - accuracy: 0.9923 - val_loss: 12.0493 - val_accuracy: 0.3047\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.6791 - accuracy: 0.9923 - val_loss: 12.0797 - val_accuracy: 0.3047\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6794 - accuracy: 0.9924 - val_loss: 12.1077 - val_accuracy: 0.3045\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6798 - accuracy: 0.9924 - val_loss: 12.1354 - val_accuracy: 0.3045\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.6801 - accuracy: 0.9924 - val_loss: 12.1598 - val_accuracy: 0.3044\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.6805 - accuracy: 0.9924 - val_loss: 12.1827 - val_accuracy: 0.3041\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6808 - accuracy: 0.9924 - val_loss: 12.2033 - val_accuracy: 0.3038\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6812 - accuracy: 0.9924 - val_loss: 12.2229 - val_accuracy: 0.3037\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.6815 - accuracy: 0.9924 - val_loss: 12.2396 - val_accuracy: 0.3035\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.6818 - accuracy: 0.9925 - val_loss: 12.2550 - val_accuracy: 0.3036\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6822 - accuracy: 0.9925 - val_loss: 12.2672 - val_accuracy: 0.3036\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6825 - accuracy: 0.9926 - val_loss: 12.2772 - val_accuracy: 0.3036\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.6828 - accuracy: 0.9926 - val_loss: 12.2857 - val_accuracy: 0.3036\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6831 - accuracy: 0.9926 - val_loss: 12.2920 - val_accuracy: 0.3036\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6835 - accuracy: 0.9926 - val_loss: 12.2977 - val_accuracy: 0.3035\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6838 - accuracy: 0.9927 - val_loss: 12.3030 - val_accuracy: 0.3034\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6841 - accuracy: 0.9927 - val_loss: 12.3078 - val_accuracy: 0.3033\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6844 - accuracy: 0.9927 - val_loss: 12.3117 - val_accuracy: 0.3033\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6847 - accuracy: 0.9928 - val_loss: 12.3138 - val_accuracy: 0.3033\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6851 - accuracy: 0.9928 - val_loss: 12.3151 - val_accuracy: 0.3033\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6854 - accuracy: 0.9929 - val_loss: 12.3159 - val_accuracy: 0.3033\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: -0.6857 - accuracy: 0.9929 - val_loss: 12.3166 - val_accuracy: 0.3031\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6860 - accuracy: 0.9929 - val_loss: 12.3151 - val_accuracy: 0.3032\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.6863 - accuracy: 0.9930 - val_loss: 12.3135 - val_accuracy: 0.3033\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.6866 - accuracy: 0.9930 - val_loss: 12.3104 - val_accuracy: 0.3034\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6869 - accuracy: 0.9930 - val_loss: 12.3067 - val_accuracy: 0.3037\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6872 - accuracy: 0.9931 - val_loss: 12.3026 - val_accuracy: 0.3038\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6875 - accuracy: 0.9931 - val_loss: 12.2990 - val_accuracy: 0.3040\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.6877 - accuracy: 0.9931 - val_loss: 12.2948 - val_accuracy: 0.3040\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6880 - accuracy: 0.9931 - val_loss: 12.2912 - val_accuracy: 0.3041\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6883 - accuracy: 0.9932 - val_loss: 12.2878 - val_accuracy: 0.3043\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6886 - accuracy: 0.9932 - val_loss: 12.2850 - val_accuracy: 0.3043\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.6889 - accuracy: 0.9932 - val_loss: 12.2815 - val_accuracy: 0.3044\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6891 - accuracy: 0.9932 - val_loss: 12.2774 - val_accuracy: 0.3045\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6894 - accuracy: 0.9933 - val_loss: 12.2734 - val_accuracy: 0.3045\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6896 - accuracy: 0.9933 - val_loss: 12.2681 - val_accuracy: 0.3046\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6899 - accuracy: 0.9933 - val_loss: 12.2614 - val_accuracy: 0.3049\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.6902 - accuracy: 0.9933 - val_loss: 12.2550 - val_accuracy: 0.3050\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.6904 - accuracy: 0.9934 - val_loss: 12.2479 - val_accuracy: 0.3051\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6907 - accuracy: 0.9934 - val_loss: 12.2405 - val_accuracy: 0.3054\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6909 - accuracy: 0.9934 - val_loss: 12.2329 - val_accuracy: 0.3056\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.6912 - accuracy: 0.9934 - val_loss: 12.2256 - val_accuracy: 0.3058\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6914 - accuracy: 0.9935 - val_loss: 12.2170 - val_accuracy: 0.3061\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.6917 - accuracy: 0.9935 - val_loss: 12.2087 - val_accuracy: 0.3065\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.6919 - accuracy: 0.9935 - val_loss: 12.1999 - val_accuracy: 0.3071\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.6921 - accuracy: 0.9935 - val_loss: 12.1905 - val_accuracy: 0.3075\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.6924 - accuracy: 0.9936 - val_loss: 12.1808 - val_accuracy: 0.3081\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6926 - accuracy: 0.9936 - val_loss: 12.1708 - val_accuracy: 0.3089\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6928 - accuracy: 0.9936 - val_loss: 12.1598 - val_accuracy: 0.3096\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6931 - accuracy: 0.9936 - val_loss: 12.1500 - val_accuracy: 0.3104\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 155ms/step - loss: -0.6933 - accuracy: 0.9936 - val_loss: 12.1390 - val_accuracy: 0.3111\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.6935 - accuracy: 0.9936 - val_loss: 12.1280 - val_accuracy: 0.3118\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6937 - accuracy: 0.9937 - val_loss: 12.1171 - val_accuracy: 0.3125\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.6940 - accuracy: 0.9937 - val_loss: 12.1053 - val_accuracy: 0.3132\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.6942 - accuracy: 0.9937 - val_loss: 12.0939 - val_accuracy: 0.3140\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 147ms/step - loss: -0.6944 - accuracy: 0.9937 - val_loss: 12.0819 - val_accuracy: 0.3148\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.6946 - accuracy: 0.9937 - val_loss: 12.0700 - val_accuracy: 0.3157\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6948 - accuracy: 0.9938 - val_loss: 12.0571 - val_accuracy: 0.3166\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6951 - accuracy: 0.9938 - val_loss: 12.0437 - val_accuracy: 0.3176\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6953 - accuracy: 0.9938 - val_loss: 12.0294 - val_accuracy: 0.3185\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.6955 - accuracy: 0.9938 - val_loss: 12.0155 - val_accuracy: 0.3194\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.6957 - accuracy: 0.9938 - val_loss: 12.0022 - val_accuracy: 0.3205\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.6959 - accuracy: 0.9938 - val_loss: 11.9878 - val_accuracy: 0.3214\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.6961 - accuracy: 0.9939 - val_loss: 11.9738 - val_accuracy: 0.3224\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6964 - accuracy: 0.9939 - val_loss: 11.9600 - val_accuracy: 0.3233\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6966 - accuracy: 0.9939 - val_loss: 11.9474 - val_accuracy: 0.3241\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.6968 - accuracy: 0.9939 - val_loss: 11.9352 - val_accuracy: 0.3252\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.6970 - accuracy: 0.9939 - val_loss: 11.9245 - val_accuracy: 0.3262\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6972 - accuracy: 0.9939 - val_loss: 11.9139 - val_accuracy: 0.3272\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6974 - accuracy: 0.9939 - val_loss: 11.9040 - val_accuracy: 0.3280\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.6976 - accuracy: 0.9940 - val_loss: 11.8949 - val_accuracy: 0.3288\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.6979 - accuracy: 0.9940 - val_loss: 11.8861 - val_accuracy: 0.3297\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.6981 - accuracy: 0.9940 - val_loss: 11.8793 - val_accuracy: 0.3304\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: -0.6983 - accuracy: 0.9940 - val_loss: 11.8725 - val_accuracy: 0.3314\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.6985 - accuracy: 0.9940 - val_loss: 11.8671 - val_accuracy: 0.3322\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.6987 - accuracy: 0.9941 - val_loss: 11.8625 - val_accuracy: 0.3330\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.6989 - accuracy: 0.9941 - val_loss: 11.8579 - val_accuracy: 0.3338\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.6992 - accuracy: 0.9941 - val_loss: 11.8541 - val_accuracy: 0.3344\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.6994 - accuracy: 0.9941 - val_loss: 11.8506 - val_accuracy: 0.3352\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.6996 - accuracy: 0.9941 - val_loss: 11.8475 - val_accuracy: 0.3359\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.6998 - accuracy: 0.9941 - val_loss: 11.8460 - val_accuracy: 0.3366\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7001 - accuracy: 0.9942 - val_loss: 11.8444 - val_accuracy: 0.3372\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7003 - accuracy: 0.9942 - val_loss: 11.8445 - val_accuracy: 0.3378\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7006 - accuracy: 0.9942 - val_loss: 11.8456 - val_accuracy: 0.3386\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7008 - accuracy: 0.9942 - val_loss: 11.8474 - val_accuracy: 0.3392\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7010 - accuracy: 0.9943 - val_loss: 11.8505 - val_accuracy: 0.3397\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7013 - accuracy: 0.9943 - val_loss: 11.8536 - val_accuracy: 0.3402\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7016 - accuracy: 0.9943 - val_loss: 11.8578 - val_accuracy: 0.3408\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7018 - accuracy: 0.9944 - val_loss: 11.8624 - val_accuracy: 0.3414\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7021 - accuracy: 0.9944 - val_loss: 11.8684 - val_accuracy: 0.3420\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7024 - accuracy: 0.9944 - val_loss: 11.8754 - val_accuracy: 0.3425\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7026 - accuracy: 0.9944 - val_loss: 11.8837 - val_accuracy: 0.3429\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7029 - accuracy: 0.9944 - val_loss: 11.8934 - val_accuracy: 0.3433\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7032 - accuracy: 0.9944 - val_loss: 11.9024 - val_accuracy: 0.3439\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7035 - accuracy: 0.9945 - val_loss: 11.9152 - val_accuracy: 0.3443\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.7038 - accuracy: 0.9945 - val_loss: 11.9292 - val_accuracy: 0.3446\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.7041 - accuracy: 0.9945 - val_loss: 11.9446 - val_accuracy: 0.3448\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7043 - accuracy: 0.9945 - val_loss: 11.9610 - val_accuracy: 0.3451\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7046 - accuracy: 0.9945 - val_loss: 11.9769 - val_accuracy: 0.3454\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7049 - accuracy: 0.9946 - val_loss: 11.9935 - val_accuracy: 0.3456\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7052 - accuracy: 0.9946 - val_loss: 12.0099 - val_accuracy: 0.3460\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7054 - accuracy: 0.9946 - val_loss: 12.0261 - val_accuracy: 0.3463\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7057 - accuracy: 0.9946 - val_loss: 12.0410 - val_accuracy: 0.3467\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7060 - accuracy: 0.9947 - val_loss: 12.0555 - val_accuracy: 0.3471\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.7063 - accuracy: 0.9947 - val_loss: 12.0698 - val_accuracy: 0.3476\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7066 - accuracy: 0.9947 - val_loss: 12.0823 - val_accuracy: 0.3480\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7069 - accuracy: 0.9947 - val_loss: 12.0927 - val_accuracy: 0.3486\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7072 - accuracy: 0.9947 - val_loss: 12.1017 - val_accuracy: 0.3492\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7075 - accuracy: 0.9948 - val_loss: 12.1100 - val_accuracy: 0.3497\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7078 - accuracy: 0.9948 - val_loss: 12.1171 - val_accuracy: 0.3503\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7081 - accuracy: 0.9948 - val_loss: 12.1226 - val_accuracy: 0.3510\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.7084 - accuracy: 0.9948 - val_loss: 12.1267 - val_accuracy: 0.3516\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7088 - accuracy: 0.9949 - val_loss: 12.1287 - val_accuracy: 0.3525\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7091 - accuracy: 0.9949 - val_loss: 12.1295 - val_accuracy: 0.3533\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7094 - accuracy: 0.9950 - val_loss: 12.1286 - val_accuracy: 0.3541\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7097 - accuracy: 0.9951 - val_loss: 12.1268 - val_accuracy: 0.3549\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7101 - accuracy: 0.9952 - val_loss: 12.1231 - val_accuracy: 0.3557\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7104 - accuracy: 0.9952 - val_loss: 12.1192 - val_accuracy: 0.3564\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7108 - accuracy: 0.9953 - val_loss: 12.1152 - val_accuracy: 0.3572\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7112 - accuracy: 0.9954 - val_loss: 12.1111 - val_accuracy: 0.3580\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7115 - accuracy: 0.9954 - val_loss: 12.1066 - val_accuracy: 0.3587\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7119 - accuracy: 0.9955 - val_loss: 12.1027 - val_accuracy: 0.3596\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7123 - accuracy: 0.9955 - val_loss: 12.0993 - val_accuracy: 0.3603\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7126 - accuracy: 0.9956 - val_loss: 12.0960 - val_accuracy: 0.3611\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7130 - accuracy: 0.9956 - val_loss: 12.0948 - val_accuracy: 0.3618\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7134 - accuracy: 0.9957 - val_loss: 12.0916 - val_accuracy: 0.3625\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7138 - accuracy: 0.9957 - val_loss: 12.0898 - val_accuracy: 0.3632\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.7142 - accuracy: 0.9958 - val_loss: 12.0872 - val_accuracy: 0.3639\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7147 - accuracy: 0.9958 - val_loss: 12.0860 - val_accuracy: 0.3645\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7151 - accuracy: 0.9959 - val_loss: 12.0849 - val_accuracy: 0.3652\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.7155 - accuracy: 0.9959 - val_loss: 12.0836 - val_accuracy: 0.3660\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7159 - accuracy: 0.9960 - val_loss: 12.0832 - val_accuracy: 0.3668\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7163 - accuracy: 0.9960 - val_loss: 12.0837 - val_accuracy: 0.3674\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7168 - accuracy: 0.9960 - val_loss: 12.0845 - val_accuracy: 0.3681\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 150ms/step - loss: -0.7172 - accuracy: 0.9960 - val_loss: 12.0862 - val_accuracy: 0.3688\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7176 - accuracy: 0.9960 - val_loss: 12.0891 - val_accuracy: 0.3693\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.7180 - accuracy: 0.9961 - val_loss: 12.0937 - val_accuracy: 0.3699\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7185 - accuracy: 0.9961 - val_loss: 12.0988 - val_accuracy: 0.3703\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.7189 - accuracy: 0.9962 - val_loss: 12.1051 - val_accuracy: 0.3708\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.7193 - accuracy: 0.9962 - val_loss: 12.1131 - val_accuracy: 0.3712\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: -0.7197 - accuracy: 0.9962 - val_loss: 12.1195 - val_accuracy: 0.3716\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7201 - accuracy: 0.9962 - val_loss: 12.1279 - val_accuracy: 0.3720\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: -0.7205 - accuracy: 0.9963 - val_loss: 12.1366 - val_accuracy: 0.3723\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7209 - accuracy: 0.9963 - val_loss: 12.1445 - val_accuracy: 0.3725\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7212 - accuracy: 0.9963 - val_loss: 12.1515 - val_accuracy: 0.3729\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7216 - accuracy: 0.9963 - val_loss: 12.1592 - val_accuracy: 0.3731\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7219 - accuracy: 0.9963 - val_loss: 12.1664 - val_accuracy: 0.3733\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: -0.7223 - accuracy: 0.9963 - val_loss: 12.1732 - val_accuracy: 0.3736\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7226 - accuracy: 0.9963 - val_loss: 12.1786 - val_accuracy: 0.3739\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7229 - accuracy: 0.9963 - val_loss: 12.1831 - val_accuracy: 0.3742\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7232 - accuracy: 0.9963 - val_loss: 12.1869 - val_accuracy: 0.3745\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: -0.7235 - accuracy: 0.9963 - val_loss: 12.1914 - val_accuracy: 0.3747\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7238 - accuracy: 0.9963 - val_loss: 12.1966 - val_accuracy: 0.3749\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.7241 - accuracy: 0.9963 - val_loss: 12.2002 - val_accuracy: 0.3750\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7243 - accuracy: 0.9963 - val_loss: 12.2028 - val_accuracy: 0.3751\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.7246 - accuracy: 0.9964 - val_loss: 12.2040 - val_accuracy: 0.3752\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.7249 - accuracy: 0.9964 - val_loss: 12.2038 - val_accuracy: 0.3755\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7252 - accuracy: 0.9964 - val_loss: 12.2010 - val_accuracy: 0.3756\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7255 - accuracy: 0.9963 - val_loss: 12.1963 - val_accuracy: 0.3757\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.7258 - accuracy: 0.9963 - val_loss: 12.1860 - val_accuracy: 0.3759\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.7261 - accuracy: 0.9963 - val_loss: 12.1709 - val_accuracy: 0.3761\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7263 - accuracy: 0.9963 - val_loss: 12.1545 - val_accuracy: 0.3763\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7265 - accuracy: 0.9963 - val_loss: 12.1352 - val_accuracy: 0.3765\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7267 - accuracy: 0.9963 - val_loss: 12.1136 - val_accuracy: 0.3769\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.7269 - accuracy: 0.9963 - val_loss: 12.0895 - val_accuracy: 0.3772\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7271 - accuracy: 0.9963 - val_loss: 12.0641 - val_accuracy: 0.3777\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.7273 - accuracy: 0.9963 - val_loss: 12.0369 - val_accuracy: 0.3781\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.7274 - accuracy: 0.9963 - val_loss: 12.0082 - val_accuracy: 0.3786\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7276 - accuracy: 0.9963 - val_loss: 11.9784 - val_accuracy: 0.3790\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7278 - accuracy: 0.9963 - val_loss: 11.9475 - val_accuracy: 0.3796\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7279 - accuracy: 0.9963 - val_loss: 11.9167 - val_accuracy: 0.3803\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.7281 - accuracy: 0.9963 - val_loss: 11.8831 - val_accuracy: 0.3810\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7283 - accuracy: 0.9963 - val_loss: 11.8493 - val_accuracy: 0.3816\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7284 - accuracy: 0.9963 - val_loss: 11.8149 - val_accuracy: 0.3826\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.7286 - accuracy: 0.9963 - val_loss: 11.7832 - val_accuracy: 0.3835\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7288 - accuracy: 0.9963 - val_loss: 11.7520 - val_accuracy: 0.3842\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7289 - accuracy: 0.9963 - val_loss: 11.7211 - val_accuracy: 0.3851\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7291 - accuracy: 0.9963 - val_loss: 11.6907 - val_accuracy: 0.3860\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7293 - accuracy: 0.9963 - val_loss: 11.6622 - val_accuracy: 0.3869\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7294 - accuracy: 0.9962 - val_loss: 11.6350 - val_accuracy: 0.3877\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7296 - accuracy: 0.9962 - val_loss: 11.6092 - val_accuracy: 0.3886\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7298 - accuracy: 0.9962 - val_loss: 11.5843 - val_accuracy: 0.3893\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7299 - accuracy: 0.9962 - val_loss: 11.5593 - val_accuracy: 0.3900\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7301 - accuracy: 0.9962 - val_loss: 11.5365 - val_accuracy: 0.3907\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7302 - accuracy: 0.9962 - val_loss: 11.5151 - val_accuracy: 0.3914\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7304 - accuracy: 0.9962 - val_loss: 11.4953 - val_accuracy: 0.3919\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7306 - accuracy: 0.9962 - val_loss: 11.4777 - val_accuracy: 0.3925\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7307 - accuracy: 0.9962 - val_loss: 11.4615 - val_accuracy: 0.3931\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.7309 - accuracy: 0.9961 - val_loss: 11.4467 - val_accuracy: 0.3936\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7310 - accuracy: 0.9961 - val_loss: 11.4345 - val_accuracy: 0.3941\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7312 - accuracy: 0.9961 - val_loss: 11.4243 - val_accuracy: 0.3946\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7313 - accuracy: 0.9961 - val_loss: 11.4156 - val_accuracy: 0.3950\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7315 - accuracy: 0.9961 - val_loss: 11.4098 - val_accuracy: 0.3953\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7316 - accuracy: 0.9961 - val_loss: 11.4068 - val_accuracy: 0.3956\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: -0.7318 - accuracy: 0.9961 - val_loss: 11.4049 - val_accuracy: 0.3959\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7319 - accuracy: 0.9961 - val_loss: 11.4041 - val_accuracy: 0.3962\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7321 - accuracy: 0.9962 - val_loss: 11.4050 - val_accuracy: 0.3966\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7322 - accuracy: 0.9962 - val_loss: 11.4072 - val_accuracy: 0.3968\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7324 - accuracy: 0.9962 - val_loss: 11.4119 - val_accuracy: 0.3970\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7325 - accuracy: 0.9962 - val_loss: 11.4166 - val_accuracy: 0.3974\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7327 - accuracy: 0.9962 - val_loss: 11.4216 - val_accuracy: 0.3978\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7328 - accuracy: 0.9962 - val_loss: 11.4267 - val_accuracy: 0.3981\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7330 - accuracy: 0.9962 - val_loss: 11.4326 - val_accuracy: 0.3984\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7331 - accuracy: 0.9962 - val_loss: 11.4382 - val_accuracy: 0.3988\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7332 - accuracy: 0.9962 - val_loss: 11.4429 - val_accuracy: 0.3994\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7334 - accuracy: 0.9962 - val_loss: 11.4475 - val_accuracy: 0.3999\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.7335 - accuracy: 0.9962 - val_loss: 11.4517 - val_accuracy: 0.4005\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7337 - accuracy: 0.9963 - val_loss: 11.4551 - val_accuracy: 0.4011\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 151ms/step - loss: -0.7338 - accuracy: 0.9962 - val_loss: 11.4587 - val_accuracy: 0.4015\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7339 - accuracy: 0.9962 - val_loss: 11.4614 - val_accuracy: 0.4022\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7341 - accuracy: 0.9962 - val_loss: 11.4641 - val_accuracy: 0.4029\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.7342 - accuracy: 0.9963 - val_loss: 11.4648 - val_accuracy: 0.4035\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 140ms/step - loss: -0.7344 - accuracy: 0.9963 - val_loss: 11.4640 - val_accuracy: 0.4041\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.7345 - accuracy: 0.9963 - val_loss: 11.4624 - val_accuracy: 0.4049\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7346 - accuracy: 0.9963 - val_loss: 11.4583 - val_accuracy: 0.4055\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7348 - accuracy: 0.9963 - val_loss: 11.4525 - val_accuracy: 0.4064\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.7349 - accuracy: 0.9963 - val_loss: 11.4444 - val_accuracy: 0.4071\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7350 - accuracy: 0.9963 - val_loss: 11.4354 - val_accuracy: 0.4080\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.7352 - accuracy: 0.9963 - val_loss: 11.4247 - val_accuracy: 0.4086\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: -0.7353 - accuracy: 0.9963 - val_loss: 11.4121 - val_accuracy: 0.4095\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7355 - accuracy: 0.9963 - val_loss: 11.3969 - val_accuracy: 0.4103\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7356 - accuracy: 0.9964 - val_loss: 11.3802 - val_accuracy: 0.4113\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7357 - accuracy: 0.9964 - val_loss: 11.3624 - val_accuracy: 0.4123\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.7359 - accuracy: 0.9964 - val_loss: 11.3436 - val_accuracy: 0.4132\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7360 - accuracy: 0.9964 - val_loss: 11.3237 - val_accuracy: 0.4142\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7361 - accuracy: 0.9964 - val_loss: 11.3027 - val_accuracy: 0.4154\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7363 - accuracy: 0.9964 - val_loss: 11.2811 - val_accuracy: 0.4165\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 135ms/step - loss: -0.7364 - accuracy: 0.9964 - val_loss: 11.2580 - val_accuracy: 0.4176\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7365 - accuracy: 0.9964 - val_loss: 11.2342 - val_accuracy: 0.4187\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7367 - accuracy: 0.9964 - val_loss: 11.2104 - val_accuracy: 0.4198\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.7368 - accuracy: 0.9964 - val_loss: 11.1860 - val_accuracy: 0.4209\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.7370 - accuracy: 0.9964 - val_loss: 11.1612 - val_accuracy: 0.4221\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7371 - accuracy: 0.9964 - val_loss: 11.1355 - val_accuracy: 0.4234\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7372 - accuracy: 0.9964 - val_loss: 11.1090 - val_accuracy: 0.4246\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.7374 - accuracy: 0.9964 - val_loss: 11.0821 - val_accuracy: 0.4258\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7375 - accuracy: 0.9964 - val_loss: 11.0548 - val_accuracy: 0.4270\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.7376 - accuracy: 0.9964 - val_loss: 11.0271 - val_accuracy: 0.4283\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7378 - accuracy: 0.9965 - val_loss: 10.9989 - val_accuracy: 0.4295\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7379 - accuracy: 0.9965 - val_loss: 10.9704 - val_accuracy: 0.4308\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7381 - accuracy: 0.9965 - val_loss: 10.9421 - val_accuracy: 0.4320\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7382 - accuracy: 0.9965 - val_loss: 10.9134 - val_accuracy: 0.4334\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7383 - accuracy: 0.9965 - val_loss: 10.8845 - val_accuracy: 0.4348\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7385 - accuracy: 0.9965 - val_loss: 10.8554 - val_accuracy: 0.4362\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7386 - accuracy: 0.9965 - val_loss: 10.8268 - val_accuracy: 0.4373\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7387 - accuracy: 0.9965 - val_loss: 10.7985 - val_accuracy: 0.4385\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.7388 - accuracy: 0.9966 - val_loss: 10.7706 - val_accuracy: 0.4397\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7390 - accuracy: 0.9966 - val_loss: 10.7432 - val_accuracy: 0.4409\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7391 - accuracy: 0.9966 - val_loss: 10.7166 - val_accuracy: 0.4420\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7392 - accuracy: 0.9966 - val_loss: 10.6901 - val_accuracy: 0.4432\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7393 - accuracy: 0.9966 - val_loss: 10.6645 - val_accuracy: 0.4442\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: -0.7394 - accuracy: 0.9966 - val_loss: 10.6399 - val_accuracy: 0.4453\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7396 - accuracy: 0.9966 - val_loss: 10.6163 - val_accuracy: 0.4464\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.7397 - accuracy: 0.9966 - val_loss: 10.5934 - val_accuracy: 0.4475\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: -0.7398 - accuracy: 0.9967 - val_loss: 10.5714 - val_accuracy: 0.4485\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7399 - accuracy: 0.9967 - val_loss: 10.5506 - val_accuracy: 0.4493\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7400 - accuracy: 0.9967 - val_loss: 10.5315 - val_accuracy: 0.4503\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7401 - accuracy: 0.9967 - val_loss: 10.5133 - val_accuracy: 0.4512\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7402 - accuracy: 0.9967 - val_loss: 10.4971 - val_accuracy: 0.4520\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7403 - accuracy: 0.9967 - val_loss: 10.4816 - val_accuracy: 0.4528\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7405 - accuracy: 0.9967 - val_loss: 10.4673 - val_accuracy: 0.4535\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7406 - accuracy: 0.9967 - val_loss: 10.4546 - val_accuracy: 0.4543\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7407 - accuracy: 0.9967 - val_loss: 10.4431 - val_accuracy: 0.4550\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7408 - accuracy: 0.9967 - val_loss: 10.4332 - val_accuracy: 0.4555\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7409 - accuracy: 0.9967 - val_loss: 10.4246 - val_accuracy: 0.4561\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7410 - accuracy: 0.9968 - val_loss: 10.4173 - val_accuracy: 0.4566\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7411 - accuracy: 0.9968 - val_loss: 10.4110 - val_accuracy: 0.4570\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7412 - accuracy: 0.9968 - val_loss: 10.4062 - val_accuracy: 0.4575\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7413 - accuracy: 0.9968 - val_loss: 10.4023 - val_accuracy: 0.4579\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7414 - accuracy: 0.9968 - val_loss: 10.3996 - val_accuracy: 0.4582\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7415 - accuracy: 0.9968 - val_loss: 10.3978 - val_accuracy: 0.4584\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7416 - accuracy: 0.9969 - val_loss: 10.3972 - val_accuracy: 0.4587\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7417 - accuracy: 0.9969 - val_loss: 10.3977 - val_accuracy: 0.4589\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7418 - accuracy: 0.9969 - val_loss: 10.3983 - val_accuracy: 0.4590\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7419 - accuracy: 0.9969 - val_loss: 10.4001 - val_accuracy: 0.4592\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7420 - accuracy: 0.9969 - val_loss: 10.4020 - val_accuracy: 0.4593\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7421 - accuracy: 0.9969 - val_loss: 10.4046 - val_accuracy: 0.4594\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7422 - accuracy: 0.9969 - val_loss: 10.4079 - val_accuracy: 0.4595\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7423 - accuracy: 0.9969 - val_loss: 10.4115 - val_accuracy: 0.4596\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7424 - accuracy: 0.9969 - val_loss: 10.4156 - val_accuracy: 0.4597\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.7425 - accuracy: 0.9969 - val_loss: 10.4201 - val_accuracy: 0.4597\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7426 - accuracy: 0.9969 - val_loss: 10.4253 - val_accuracy: 0.4597\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7427 - accuracy: 0.9970 - val_loss: 10.4305 - val_accuracy: 0.4597\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7428 - accuracy: 0.9970 - val_loss: 10.4359 - val_accuracy: 0.4597\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.7428 - accuracy: 0.9970 - val_loss: 10.4415 - val_accuracy: 0.4597\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7429 - accuracy: 0.9970 - val_loss: 10.4473 - val_accuracy: 0.4597\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7430 - accuracy: 0.9970 - val_loss: 10.4535 - val_accuracy: 0.4596\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7431 - accuracy: 0.9970 - val_loss: 10.4599 - val_accuracy: 0.4597\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.7432 - accuracy: 0.9970 - val_loss: 10.4668 - val_accuracy: 0.4596\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: -0.7432 - accuracy: 0.9971 - val_loss: 10.4734 - val_accuracy: 0.4596\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7433 - accuracy: 0.9971 - val_loss: 10.4802 - val_accuracy: 0.4596\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: -0.7434 - accuracy: 0.9970 - val_loss: 10.4869 - val_accuracy: 0.4595\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7435 - accuracy: 0.9971 - val_loss: 10.4937 - val_accuracy: 0.4595\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7435 - accuracy: 0.9971 - val_loss: 10.5007 - val_accuracy: 0.4594\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7436 - accuracy: 0.9971 - val_loss: 10.5077 - val_accuracy: 0.4594\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7437 - accuracy: 0.9971 - val_loss: 10.5149 - val_accuracy: 0.4594\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7437 - accuracy: 0.9971 - val_loss: 10.5221 - val_accuracy: 0.4593\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.7438 - accuracy: 0.9971 - val_loss: 10.5292 - val_accuracy: 0.4593\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7439 - accuracy: 0.9971 - val_loss: 10.5365 - val_accuracy: 0.4594\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7440 - accuracy: 0.9971 - val_loss: 10.5437 - val_accuracy: 0.4594\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7440 - accuracy: 0.9972 - val_loss: 10.5511 - val_accuracy: 0.4593\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7441 - accuracy: 0.9972 - val_loss: 10.5583 - val_accuracy: 0.4594\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7442 - accuracy: 0.9972 - val_loss: 10.5652 - val_accuracy: 0.4594\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7442 - accuracy: 0.9972 - val_loss: 10.5720 - val_accuracy: 0.4593\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: -0.7443 - accuracy: 0.9972 - val_loss: 10.5786 - val_accuracy: 0.4594\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7443 - accuracy: 0.9972 - val_loss: 10.5853 - val_accuracy: 0.4594\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.7444 - accuracy: 0.9972 - val_loss: 10.5917 - val_accuracy: 0.4593\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: -0.7445 - accuracy: 0.9972 - val_loss: 10.5984 - val_accuracy: 0.4593\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7445 - accuracy: 0.9972 - val_loss: 10.6049 - val_accuracy: 0.4593\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: -0.7446 - accuracy: 0.9972 - val_loss: 10.6117 - val_accuracy: 0.4593\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 139ms/step - loss: -0.7447 - accuracy: 0.9972 - val_loss: 10.6177 - val_accuracy: 0.4594\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7447 - accuracy: 0.9972 - val_loss: 10.6238 - val_accuracy: 0.4593\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7448 - accuracy: 0.9972 - val_loss: 10.6297 - val_accuracy: 0.4594\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 149ms/step - loss: -0.7449 - accuracy: 0.9972 - val_loss: 10.6353 - val_accuracy: 0.4594\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7449 - accuracy: 0.9972 - val_loss: 10.6408 - val_accuracy: 0.4594\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7450 - accuracy: 0.9972 - val_loss: 10.6458 - val_accuracy: 0.4595\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7450 - accuracy: 0.9972 - val_loss: 10.6503 - val_accuracy: 0.4596\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7451 - accuracy: 0.9972 - val_loss: 10.6548 - val_accuracy: 0.4597\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7451 - accuracy: 0.9972 - val_loss: 10.6590 - val_accuracy: 0.4598\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7452 - accuracy: 0.9972 - val_loss: 10.6626 - val_accuracy: 0.4599\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7453 - accuracy: 0.9972 - val_loss: 10.6660 - val_accuracy: 0.4600\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 145ms/step - loss: -0.7453 - accuracy: 0.9972 - val_loss: 10.6689 - val_accuracy: 0.4601\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7454 - accuracy: 0.9972 - val_loss: 10.6719 - val_accuracy: 0.4602\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7454 - accuracy: 0.9972 - val_loss: 10.6743 - val_accuracy: 0.4603\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: -0.7455 - accuracy: 0.9972 - val_loss: 10.6763 - val_accuracy: 0.4605\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 146ms/step - loss: -0.7455 - accuracy: 0.9973 - val_loss: 10.6780 - val_accuracy: 0.4606\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: -0.7456 - accuracy: 0.9973 - val_loss: 10.6794 - val_accuracy: 0.4607\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7457 - accuracy: 0.9973 - val_loss: 10.6808 - val_accuracy: 0.4609\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7457 - accuracy: 0.9973 - val_loss: 10.6816 - val_accuracy: 0.4611\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7458 - accuracy: 0.9973 - val_loss: 10.6823 - val_accuracy: 0.4613\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7458 - accuracy: 0.9973 - val_loss: 10.6828 - val_accuracy: 0.4615\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7459 - accuracy: 0.9973 - val_loss: 10.6826 - val_accuracy: 0.4617\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7459 - accuracy: 0.9973 - val_loss: 10.6822 - val_accuracy: 0.4619\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7460 - accuracy: 0.9973 - val_loss: 10.6817 - val_accuracy: 0.4621\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7460 - accuracy: 0.9973 - val_loss: 10.6812 - val_accuracy: 0.4624\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: -0.7461 - accuracy: 0.9974 - val_loss: 10.6806 - val_accuracy: 0.4626\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7461 - accuracy: 0.9974 - val_loss: 10.6796 - val_accuracy: 0.4629\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: -0.7462 - accuracy: 0.9974 - val_loss: 10.6785 - val_accuracy: 0.4631\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7462 - accuracy: 0.9974 - val_loss: 10.6771 - val_accuracy: 0.4633\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7462 - accuracy: 0.9974 - val_loss: 10.6757 - val_accuracy: 0.4635\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: -0.7463 - accuracy: 0.9974 - val_loss: 10.6741 - val_accuracy: 0.4637\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7463 - accuracy: 0.9974 - val_loss: 10.6723 - val_accuracy: 0.4639\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 124ms/step - loss: -0.7464 - accuracy: 0.9974 - val_loss: 10.6707 - val_accuracy: 0.4641\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: -0.7464 - accuracy: 0.9974 - val_loss: 10.6686 - val_accuracy: 0.4643\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 169ms/step - loss: -0.7465 - accuracy: 0.9974 - val_loss: 10.6666 - val_accuracy: 0.4645\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: -0.7465 - accuracy: 0.9974 - val_loss: 10.6646 - val_accuracy: 0.4647\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7465 - accuracy: 0.9974 - val_loss: 10.6627 - val_accuracy: 0.4650\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: -0.7466 - accuracy: 0.9974 - val_loss: 10.6606 - val_accuracy: 0.4652\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7466 - accuracy: 0.9974 - val_loss: 10.6587 - val_accuracy: 0.4654\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7467 - accuracy: 0.9974 - val_loss: 10.6565 - val_accuracy: 0.4657\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: -0.7467 - accuracy: 0.9974 - val_loss: 10.6545 - val_accuracy: 0.4659\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7467 - accuracy: 0.9974 - val_loss: 10.6523 - val_accuracy: 0.4660\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.7468 - accuracy: 0.9974 - val_loss: 10.6500 - val_accuracy: 0.4662\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7468 - accuracy: 0.9974 - val_loss: 10.6478 - val_accuracy: 0.4664\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7469 - accuracy: 0.9974 - val_loss: 10.6457 - val_accuracy: 0.4667\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7469 - accuracy: 0.9975 - val_loss: 10.6434 - val_accuracy: 0.4669\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7469 - accuracy: 0.9975 - val_loss: 10.6411 - val_accuracy: 0.4672\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: -0.7470 - accuracy: 0.9974 - val_loss: 10.6392 - val_accuracy: 0.4674\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: -0.7470 - accuracy: 0.9975 - val_loss: 10.6370 - val_accuracy: 0.4676\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: -0.7470 - accuracy: 0.9975 - val_loss: 10.6346 - val_accuracy: 0.4679\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7471 - accuracy: 0.9974 - val_loss: 10.6325 - val_accuracy: 0.4681\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7471 - accuracy: 0.9975 - val_loss: 10.6305 - val_accuracy: 0.4682\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7471 - accuracy: 0.9974 - val_loss: 10.6283 - val_accuracy: 0.4684\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7472 - accuracy: 0.9974 - val_loss: 10.6265 - val_accuracy: 0.4686\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: -0.7472 - accuracy: 0.9975 - val_loss: 10.6247 - val_accuracy: 0.4688\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: -0.7472 - accuracy: 0.9975 - val_loss: 10.6231 - val_accuracy: 0.4689\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: -0.7473 - accuracy: 0.9975 - val_loss: 10.6214 - val_accuracy: 0.4691\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: -0.7473 - accuracy: 0.9975 - val_loss: 10.6197 - val_accuracy: 0.4692\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7473 - accuracy: 0.9975 - val_loss: 10.6182 - val_accuracy: 0.4693\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: -0.7473 - accuracy: 0.9975 - val_loss: 10.6166 - val_accuracy: 0.4695\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: -0.7474 - accuracy: 0.9975 - val_loss: 10.6151 - val_accuracy: 0.4696\n"
     ]
    }
   ],
   "source": [
    "UNet.compile(\n",
    "    loss = MyLoss,\n",
    "    optimizer = optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "x_train, y_train = load_training_data(train_img_path,train_label_path,0)\n",
    "x_val, y_val = load_training_data(val_img_path,val_label_path,0)\n",
    "\n",
    "history = UNet.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_val,y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "train = UNet.predict(x_train)[0]\n",
    "train = np.argmax(train,axis=2)\n",
    "for i, score in enumerate(scores):\n",
    "    train[train==i] = score\n",
    "\n",
    "test = UNet.predict(x_val)[0]\n",
    "test = np.argmax(test,axis=2)\n",
    "for i, score in enumerate(scores):\n",
    "    test[test==i] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,4)\n",
    "axs[0].imshow(plt.imread('C:/Users/nwuen/Documents/deepdart_aml/dataset/cropped_images/800/d1_02_04_2020/IMG_1081.JPG')[400-128:400+128,400-128:400+128])\n",
    "axs[1].imshow(np.dot(y_train[0],scores),cmap='gray')\n",
    "axs[2].imshow(train,cmap='gray')\n",
    "axs[3].imshow(test,cmap='gray')\n",
    "plt.show()\n",
    "imwrite('test.tif',train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_folder</th>\n",
       "      <th>img_name</th>\n",
       "      <th>bbox</th>\n",
       "      <th>xy</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1081.JPG</td>\n",
       "      <td>[2297, 3949, 676, 2328]</td>\n",
       "      <td>[[0.4350282485875706, 0.1285310734463277], [0....</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1082.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1083.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1084.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1_02_04_2020</td>\n",
       "      <td>IMG_1085.JPG</td>\n",
       "      <td>[2267, 3803, 759, 2295]</td>\n",
       "      <td>[[0.44162326388888884, 0.12738715277777776], [...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16045</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0507.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16046</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0508.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16047</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0509.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16048</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0510.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16049</th>\n",
       "      <td>d2_04_05_2020</td>\n",
       "      <td>DSC_0511.JPG</td>\n",
       "      <td>[200, 2849, 969, 3618]</td>\n",
       "      <td>[[0.4369087750204756, 0.1419047415543067], [0....</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16050 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_folder      img_name                     bbox  \\\n",
       "0      d1_02_04_2020  IMG_1081.JPG  [2297, 3949, 676, 2328]   \n",
       "1      d1_02_04_2020  IMG_1082.JPG  [2267, 3803, 759, 2295]   \n",
       "2      d1_02_04_2020  IMG_1083.JPG  [2267, 3803, 759, 2295]   \n",
       "3      d1_02_04_2020  IMG_1084.JPG  [2267, 3803, 759, 2295]   \n",
       "4      d1_02_04_2020  IMG_1085.JPG  [2267, 3803, 759, 2295]   \n",
       "...              ...           ...                      ...   \n",
       "16045  d2_04_05_2020  DSC_0507.JPG   [200, 2849, 969, 3618]   \n",
       "16046  d2_04_05_2020  DSC_0508.JPG   [200, 2849, 969, 3618]   \n",
       "16047  d2_04_05_2020  DSC_0509.JPG   [200, 2849, 969, 3618]   \n",
       "16048  d2_04_05_2020  DSC_0510.JPG   [200, 2849, 969, 3618]   \n",
       "16049  d2_04_05_2020  DSC_0511.JPG   [200, 2849, 969, 3618]   \n",
       "\n",
       "                                                      xy  score  \n",
       "0      [[0.4350282485875706, 0.1285310734463277], [0....    0.0  \n",
       "1      [[0.44162326388888884, 0.12738715277777776], [...   20.0  \n",
       "2      [[0.44162326388888884, 0.12738715277777776], [...   29.0  \n",
       "3      [[0.44162326388888884, 0.12738715277777776], [...   69.0  \n",
       "4      [[0.44162326388888884, 0.12738715277777776], [...    7.0  \n",
       "...                                                  ...    ...  \n",
       "16045  [[0.4369087750204756, 0.1419047415543067], [0....   27.0  \n",
       "16046  [[0.4369087750204756, 0.1419047415543067], [0....   34.0  \n",
       "16047  [[0.4369087750204756, 0.1419047415543067], [0....    1.0  \n",
       "16048  [[0.4369087750204756, 0.1419047415543067], [0....   21.0  \n",
       "16049  [[0.4369087750204756, 0.1419047415543067], [0....   41.0  \n",
       "\n",
       "[16050 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "pd.read_pickle(f'{os.environ[\"HOME\"]}/Dokumente/deepdart_aml/labelswithscore.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1bb28a1629dcd2ce0fd8a63e2c59b027008368b3bacc8617dff119a043041546"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
